[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "We are responsible for:\n\nData analysis & reporting on key projects\nR package development & maintenance\nOutreach & engagement with the research community\n\n\n\nMeet the team\nClick on photos to view their articles and contributions\n\n\n\n\n\n\n\n\n\n\nMartin Westgate\n\nTeam Leader\n\n\n\n\n\n\n\n\n\n\nShandiya Balasubramaniam\n\nData Analyst\n\n\n\n\n\n\n\n\n\n\nAmanda Buyan\n\nData Analyst\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDax Kellie\n\nData Analyst\n\n\n\n\n\n\n\n\n\n\nOlivia Torresan\n\nSupport Officer\n\n\n\n\n\n\n\n\n\n\nFonti Kar\n\nData Analyst\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMargot Schneider\n\nProject Manager"
  },
  {
    "objectID": "galah.html",
    "href": "galah.html",
    "title": "ALA Labs",
    "section": "",
    "text": "galah\n{galah} is an R interface to biodiversity data hosted by the Atlas of Living Australia (ALA). It enables users to locate and download species occurrence records (observations, specimens, eDNA records, etc.), taxonomic information, or associated media such as images or sounds, and to restrict their queries to particular taxa or locations.  Visit the {galah} R package website to learn more about how to use galah If you have any questions, comments, or spot any bugs, email us or report an issue on our GitHub page\n\n\n\n\nGet started\nInstall from CRAN\n\ninstall.packages(\"galah\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ALA Labs",
    "section": "",
    "text": "Welcome to ALA Labs\nThis site is a resource for coding projects that use data sourced from the ALA. We hope that users will find interesting content, whether their focus is ecological modelling, data visualisation, or simply investigating the natural world through a digital lens. Enjoy!\n\n\n\n\nData visualisation\n\n\n\nClick to see related posts on each topic\n\n\n\n\n\n\n\n\n\n\nSummaries\n\n\n\n\n\n\n\n\n\nMaps\n\n\n\n\n\n\n\n\n\nTrees\n\n\n\n\n\n\n\n\nTaxonomy\n\n\n\nClick to see related posts on each topic\n\n\n\n\n\n\n\n\n\n\nPlants\n\n\n\n\n\n\n\n\n\nBirds\n\n\n\n\n\n\n\n\n\nMammals\n\n\n\n\n\n\n\n\n We value\n\n\n\n\n\n\n\n\n\n\n\n    Openness\n\nData are most useful when they are widely available and easy to use. We try to encourage the sharing of tools that make data from the Atlas of Living Australia more open and useful for everyone\n\n\n\n\n\n\n    Scientific transparency\n\nTransparency is necessary for reproducible science. We encourage that decisions, methods and deviations in our workflow are clear and transparent from the planning phase, to the retrieval and analysis of data, to the final output\n\n\n\n\n\n\n    Robust methods\n\nNo method or analytic procedure is perfect. We value consideration for strengths and limitations of each method or analysis to help choose the methods that provide robust, reliable results"
  },
  {
    "objectID": "people/Balasubramaniam_Shandiya/index.html",
    "href": "people/Balasubramaniam_Shandiya/index.html",
    "title": "Shandiya Balasubramaniam",
    "section": "",
    "text": "Bio\n\n\nShandiya is an evolutionary ecologist with interests in conservation genetics and wildlife disease. Her work as a data analyst at the ALA focuses on streamlining reproducible pathways for researchers to access and analyse open data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Posts\nMultiple colour scales in choropleth maps with {ggnewscale}Using multiple colour scales can be a great way to visually differentiate between geographic categories on a map. Here, we demonstrate this by creating a choropleth map to represent the density of plant records from the ALA across bioregions in Australia, and add multiple colour scales to differentiate marine and terrestrial records"
  },
  {
    "objectID": "people/Buyan_Amanda/index.html",
    "href": "people/Buyan_Amanda/index.html",
    "title": "Amanda Buyan",
    "section": "",
    "text": "Bio\n\n\nAmanda is a data analyst for EcoCommons, and is based at the Atlas of Living Australia. She completed her PhD in Structural Biology, and uses her extensive Python skills to manage the integration of data within EcoCommons. She also works to optimize the available scientific workflows within the platform.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Posts"
  },
  {
    "objectID": "people/Kar_Fonti/index.html",
    "href": "people/Kar_Fonti/index.html",
    "title": "Fonti Kar",
    "section": "",
    "text": "Bio\n\n\nFonti is an evolutionary biologist wearing R developer shoes. Her interests include biostatistics, reproducible science, learning about the latest coding practices and teaching others to enjoy using R. Her work at ALA as a Data Analyst involves streamlining data cleaning workflows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Posts\nConvex and alpha hulls for conservation mappingConvex hulls and alpha hulls are wonderful alternatives for visualising species distributions when a species has very few existing observations. Here, we will show you how to create these spatial polygons using data from the ALA."
  },
  {
    "objectID": "people/Kellie_Dax/index.html",
    "href": "people/Kellie_Dax/index.html",
    "title": "Dax Kellie",
    "section": "",
    "text": "Bio\n\n\nDax is an evolutionary biologist, with a PhD in biological sciences and social psychology. As a data analyst at the ALA, he tries to make data in the ALA accessible for scientists and citizen scientists to use in ways that are scientifically robust and transparent.\nDax is the primary editor of ALA Labs.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Posts\nCounting points in multipolygon shapefiles for choropleth mappingChoropleth maps are an excellent way to visualise numbers of observations in each region. When using point data, calculating the number of points in each polygon can be difficult when using shapefiles. Here we demonstrate how to extract and summarise the number of points in each polygon within a shapefile to create a choropleth map. Quantify geographic sampling bias with {sampbias}Human biases play a large role in the data we collect about species. Here we show a simple method to quantify the bias of roads, cities, rivers and airports on species observations of legless lizards in the Northern Territory Download plant species data by hexagon to make a 3D hex mapMaking plots eye-catching can be useful for science communication. Here, we show how to make 3D plots in R with the rayshader package by visualising the number of species identified from ALA observations since 2020"
  },
  {
    "objectID": "people/Schneider_Margot/index.html",
    "href": "people/Schneider_Margot/index.html",
    "title": "Margot Schneider",
    "section": "",
    "text": "Bio\n\n\nMargot is a graduate of the Australian National University (ANU) with a Bachelor of Science (Honours) on bushfire chemical ecology. She works to improve data quality in the ALA. Margot is a strong advocate for diversity and inclusion in the STEMM fields.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Posts\nConvex and alpha hulls for conservation mappingConvex hulls and alpha hulls are wonderful alternatives for visualising species distributions when a species has very few existing observations. Here, we will show you how to create these spatial polygons using data from the ALA."
  },
  {
    "objectID": "people/Torresan_Olivia/index.html",
    "href": "people/Torresan_Olivia/index.html",
    "title": "Olivia Torresan",
    "section": "",
    "text": "Bio\n\n\nOlivia is a graduate from the Australian National University (ANU), acquiring an interdisciplinary double degree in philosophy and natural resource management. At the ALA, she works as a support officer with a primary focus on monitoring the research impact of the Atlas. She is passionate about accessibility, environmental justice and diversity in STEMM.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Posts\nCounting points in multipolygon shapefiles for choropleth mappingChoropleth maps are an excellent way to visualise numbers of observations in each region. When using point data, calculating the number of points in each polygon can be difficult when using shapefiles. Here we demonstrate how to extract and summarise the number of points in each polygon within a shapefile to create a choropleth map."
  },
  {
    "objectID": "people/Westgate_Martin/index.html",
    "href": "people/Westgate_Martin/index.html",
    "title": "Martin Westgate",
    "section": "",
    "text": "Bio\n\n\nMartin leads the Science & Decision Support Team. He holds a doctorate in landscape ecology and conservation biology from the Australian National University. His work focuses on conceptual, computational and statistical tools to better understand patterns in nature.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Posts\nHex maps for species occurrence dataHex maps are a neat way to represent spatial information. Here, we show how to draw one using the most common species in the ALA database: the iconic Australian Magpie. Sunburst plots for taxonomic dataSince version 1.3.1 of galah, it has been possible to download taxonomic data using a ‘tree’ format from the data.tree package. Here I’ll demonstrate some ideas for plotting these trees using circular diagrams. Creating a color palette from an imageThere are hundreds of color palettes in the R ecosystem, but sometimes we might want to use colors from a specific image. Here I show how to use the paletter package to create a color palette for the 2020 Eucalypt of the Year: the Western Australian Gimlet."
  },
  {
    "objectID": "posts/2021-03-20_creating-a-color-palette-from-an-image/index.html",
    "href": "posts/2021-03-20_creating-a-color-palette-from-an-image/index.html",
    "title": "Creating a color palette from an image",
    "section": "",
    "text": "Author\nMartin Westgate\n\n\nDate\nMarch 2021\n\n\n\n\n\n\n\n\n\n\n\nColors in R\nColor palettes are important to people, and the R ecosystem includes literally hundreds of possible palettes. If you want a “complete” list, go and check out Emil Hvitfeldt’s list of palettes here; but in practice there are only a few that we use routinely. Our default at ALA labs is to use viridis for continuous scales, because (to quote their CRAN page) it’s color-blind friendly, perceptually uniform, and pretty. The default purple-green-yellow color scheme is lovely, but I’m a big fan of ‘magma’, which has a black-purple-orange-yellow scheme\n\nlibrary(galah)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(viridis)\n\n\n# Get field code for states/territories\nsearch_fields(\"state\") # layer: cl22 OR stateProvince\n\n# A tibble: 26 × 4\n   id      description                                               type  link \n   <chr>   <chr>                                                     <chr> <chr>\n 1 cl3     \"Western Australian Biodiversity Science Research Priori… laye… http…\n 2 cl938   \"Fruit Fly Exclusion Zone - Tri State Fruit Fly Exclusio… laye… http…\n 3 cl927   \"States including coastal waters States (including coast… laye… http…\n 4 cl22    \"Australian States and Territories Australian States and… laye… http…\n 5 cl2013  \"ASGS Australian States and Territories Australian Stati… laye… http…\n 6 cl2009  \"National Native Title Register (NNTR, Determinations of… laye… http…\n 7 cl10900 \"Australia's Indigenous forest estate (2013) v2.0 Austra… laye… http…\n 8 cl10902 \"Forests of Australia (2013) v2.0 Forests of Australia (… laye… http…\n 9 cl10903 \"Tenure of Australia's forests (2013) v2.0 Tenure of Aus… laye… http…\n10 cl11033 \"CAPAD 2020 Terrestrial The Collaborative Australian Pro… laye… http…\n# … with 16 more rows\n\n# Download record counts by state/territory\nrecords <- galah_call() %>%\n  galah_group_by(cl22) %>%\n  atlas_counts()\n\n# Add state information back to data frame\nrecords$State <- factor(seq_len(nrow(records)), labels = records$cl22) \n\n# Plot\nggplot(records, aes(x = State, y = log10(count), fill = count)) + \n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  scale_fill_viridis(option = \"magma\", begin = 0.10, end = 0.95) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\nMy default for categorical color schemes is the ‘dark2’ palette from RColorBrewer; but given the subject matter of our work, it’s worth mentioning the wonderful feather package by Shandiya Balasubramaniam, which gives colors based on Australian bird plumage.\n\n# remotes::install_github(repo = \"shandiya/feathers\")\nlibrary(feathers)\n\nrcfd <- galah_call() %>%\n  galah_identify(\"Rose-crowned Fruit-Dove\") %>%\n  galah_group_by(cl22) %>%\n  atlas_counts()\n  \nrcfd$State <- factor(seq_len(nrow(rcfd)), labels = rcfd$cl22) \n\nggplot(rcfd, aes(x = State, y = log10(count), fill = State)) + \n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  scale_fill_manual(values = get_pal(\"rose_crowned_fruit_dove\")) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\nAll of this is fine, but what if you have a specific image that you want to take colors from? A logical choice is to pick the colors you want using an image editting program, but if we want to try something automated, there are options in R as well.\n\n\nExtracting colors\nNational Eucalypt Day aims to raise awareness about Eucalypts and celebrate their influence on the lives of Australians. In honour of National Eucalypt day, we wanted to created a plot based on occurrences data held in the Atlas of Living Australia, themed using colours from actual Eucalypts.\nWe used this image from a tweet by Dean Nicolle:\n\n\nHappy 'National Eucalypt Day'!The Western Australian gimlet (Eucalyptus salubris) has just been announced as Eucalypt of the Year for 2021. Renowned for its fluted, smooth, shiny, and colourful trunk & branches. pic.twitter.com/pOsufQtxWS— Dean Nicolle (@DeanNicolle1) March 22, 2021\n\n\n\n\n\n\nImage of Eucalyptus salubris by Dean Nicolle\n\n\nFirst, get observations of the Eucalypt of the Year 2021 from ALA using the galah package. Specifically, we use atlas_counts() to determine how many records of Eucalyptus salubris are held by the ALA:\n\nn_records <- galah_call() %>%\n  galah_identify(\"Eucalyptus salubris\") %>%\n  atlas_counts()\n\nHere is what the data look like:\n\nn_records %>% head()\n\n# A tibble: 1 × 1\n  count\n  <int>\n1   851\n\n\nThen get a color scheme from images of the species in question using the paletter package (which needs to be installed from GitHub) \n\n# remotes::install_github(\"AndreaCirilloAC/paletter\")\nlibrary(paletter)\n\nimage_pal <- create_palette(\n  image_path = \"./data/Dean_Nicolle_Esalubris_image_small.jpeg\",\n  type_of_variable = \"categorical\",\n  number_of_colors = 15)\n\n\n\n\n\n\nNote that we downsized the image before running the paletter code, as large images take much longer to process.\n\n\nCreating a plot\nOnce we have this palette, the obvious question is what kind of plot to draw. We could have done a map, but those can be a bit boring. We decided to try something that represented the number of observations we had of this species at ALA, and included color, but was otherwise just a pretty picture that didn’t need to contain any further information. Rather than have a traditional x and y axis, therefore, we decided to try out the igraph package to plot the points in an interesting way.\nFirst, we create a vector containing as many points as we want to display, and distribute our colors among them as evenly as possible\n\n# create a vector to index colours\nrep_times <- floor(n_records / length(image_pal))\n\ncolour_index <- rep(seq_along(image_pal),\n  each = as.integer(rep_times))\n\nThen we can create a network using igraph, and use it to create a layout for our points\n\nlibrary(igraph)\n\ngraph_list <- lapply(c(1:15), function(a){\n  lookup <- which(colour_index == a)\n  return(\n    tibble(\n    from = lookup[c(1:(length(lookup)-1))],\n    to = lookup[c(2:length(lookup))])\n    )\n  })\ngraph_df <- as_tibble(do.call(rbind, graph_list)) %>%     # build matrix\n  tidyr::drop_na() %>%\n  as.matrix(.)\ncolour_graph <- graph_from_edgelist(graph_df)             # create network graph\n\n# convert to a set of point locations\ntest_layout <- as.data.frame(layout_nicely(colour_graph)) # convert to df\ncolnames(test_layout) <- c(\"x\", \"y\")                      # change colnames\ntest_layout$colour_index <- factor(colour_index)          # add colour_index col\n\nFinally, we draw the plot with ggplot2, removing axes with theme_void()\n\nggplot(test_layout, aes(x = x, y = y, colour = colour_index)) +\n  geom_point(size = 3, alpha = 0.9) +\n  scale_color_manual(values = image_pal) +\n  coord_fixed() +\n  theme_void() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\nThat’s it! While I like the effect here, I think the paletter package is best suited to cases where there are large areas of strongly contrasting colors; it’s less ideal for images with subtle color differences. It also doesn’t appear to have been updated lately, which may mean it’s not being supported any more. But I’m happy with this plot, and would definitely consider using it again.\n\n\nExpand for session info\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31 ucrt)\n os       Windows 10 x64 (build 19044)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_Australia.utf8\n ctype    English_Australia.utf8\n tz       Australia/Sydney\n date     2023-02-06\n pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version    date (UTC) lib source\n dplyr       * 1.1.0      2023-01-29 [1] CRAN (R 4.2.2)\n feathers    * 0.0.0.9000 2022-10-11 [1] Github (shandiya/feathers@4be766d)\n galah       * 1.5.1      2023-01-13 [1] CRAN (R 4.2.2)\n ggplot2     * 3.3.6      2022-05-03 [1] CRAN (R 4.2.1)\n htmltools   * 0.5.4      2022-12-07 [1] CRAN (R 4.2.2)\n igraph      * 1.3.4      2022-07-19 [1] CRAN (R 4.2.1)\n paletter    * 0.0.0.9000 2023-01-10 [1] Github (AndreaCirilloAC/paletter@c09605b)\n sessioninfo * 1.2.2      2021-12-06 [1] CRAN (R 4.2.1)\n viridis     * 0.6.2      2021-10-13 [1] CRAN (R 4.2.1)\n viridisLite * 0.4.1      2022-08-22 [1] CRAN (R 4.2.1)\n\n [1] C:/Users/KEL329/R-packages\n [2] C:/Users/KEL329/AppData/Local/Programs/R/R-4.2.2/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2021-04-14_hex-maps-for-species-occurrence-data/hex-maps.html",
    "href": "posts/2021-04-14_hex-maps-for-species-occurrence-data/hex-maps.html",
    "title": "Hex maps for species occurrence data",
    "section": "",
    "text": "Author\nMatilda Stevenson\nDax Kellie\nMartin Westgate\n\n\nDate\nMarch 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nArticle updated 6 February, 2023. Updates streamline code, and provide more examples of output after each step. More in-text detail has also been added about what is happening at each step.\n\n\nThe Atlas of Living Australia (ALA) holds records of magpie sightings from a number data providers like iNaturalist, eBird and BirdLife Australia. Let’s make a visualisation of Australian Bird of the Year 2018 winner, Magpies, using records held in the ALA.\n\nGetting species occurrences\nAs with any R project, a good first step is to load the required packages\n\n# packages\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(ozmaps)\nlibrary(sf)\nlibrary(hexbin)\n\nWe will use the {galah} package to download records.\nTo download species occurrence records, the {galah} package requires you to add an email registered with the ALA to galah_config(). If running this code yourself, you will need to add an email using the code below, substituting your email with myemail@email.com. This email address should be registered with the ALA, which you can do here\n\nlibrary(galah)\ngalah_config(email = \"myemail@email.com\")\n\n\n\n\nNow we can download magpie occurrence records by using atlas_occurrences(). Note that we also set our data ‘profile’ to ‘ALA’; this means we only download records that meet some basic data quality standards enforced by the atlas. This is optional, but tends to improve the quality of the data returned. (If you wish to see the data quality filters applied in the ALA profile, use search_all(profiles, \"ALA\") |> show_values())\n\nmagpie_occ <- galah_call() %>%\n  galah_identify(\"Cracticus tibicen\") %>%\n  galah_apply_profile(ALA) %>%\n  atlas_occurrences()\n\nLet’s have a look at the first few rows of the data we’ve just downloaded:\n\nmagpie_occ %>% head()\n\n# A tibble: 6 × 8\n  decimalL…¹ decim…² eventDate           scien…³ taxon…⁴ recor…⁵ dataR…⁶ occur…⁷\n       <dbl>   <dbl> <dttm>              <chr>   <chr>   <chr>   <chr>   <chr>  \n1      -45.0    169. 2019-09-04 14:00:00 Gymnor… https:… fd07f7… ALA sp… PRESENT\n2      -44.5    170. 2018-10-28 08:44:00 Gymnor… https:… 2f5933… Earth … PRESENT\n3      -44.1    170. 2019-05-02 15:18:00 Gymnor… https:… f09f13… Earth … PRESENT\n4      -43.6    147. 2019-03-10 13:00:00 Gymnor… https:… bf2044… eBird … PRESENT\n5      -43.6    147. 2018-02-05 13:00:00 Gymnor… https:… 52269e… eBird … PRESENT\n6      -43.6    147. 2018-02-05 13:00:00 Gymnor… https:… fe1644… eBird … PRESENT\n# … with abbreviated variable names ¹​decimalLatitude, ²​decimalLongitude,\n#   ³​scientificName, ⁴​taxonConceptID, ⁵​recordID, ⁶​dataResourceName,\n#   ⁷​occurrenceStatus\n\n\nFor the purpose of this exercise, we’re going to filter records not on the mainland or Tasmania.\n\nfiltered_occ <- magpie_occ %>% filter(decimalLongitude < 155,\n                                      decimalLongitude > 110,\n                                      decimalLatitude > -45,\n                                      decimalLatitude < -10)\n\n\n\nPlotting binned data\nThe easiest way to create a hex map is using the hexbin package. However, because there are some areas that have many more observations than other areas, without standardising our data the result is not very useful.\n\nggplot() +\n  geom_hex(data = filtered_occ,\n           mapping = aes(x = decimalLongitude, \n                         y = decimalLatitude), \n           bins = 47, \n           colour = \"white\") +\n  coord_sf(ylim = c(-45, -10), \n           xlim = c(110, 155)) +\n  scale_fill_gradientn(colours = c(\"#EEECEA\", \"#E06E53\")) +\n  theme_void()\n\n\n\n\nTo make a more informative hex map, in this case it might be useful to try to create our hexagons manually. We can do this by manually creating a grid of hexagons, filtering the grid to the outline of Australia, and adding our data of magpie counts to set the fill color of those hexagons. To achieve this, we first convert the map of Australia provided by ozmaps to the same coordinate system as ALA data:\n\naus <- st_transform(ozmaps::ozmap_country, 4326)\n\nNext we’ll create a grid of hexagons.\n\ngrid_all <- st_make_grid(aus, \n                         cellsize = 1, \n                         what = \"polygons\", \n                         square = FALSE,\n                         flat_topped = TRUE)\n\nggplot() +\n  geom_sf(data = grid_all)\n\n\n\n\nNow we can extract all the hexagons in our full grid that intersect our map of Australia, and filter our grid to only include those hexagons by only keeping the hexagon rows that are returned after running st_intersects().\n\n# extract rows that are within AUS land\nkeep_hexes <- st_intersects(grid_all, aus) %>%\n  as.data.frame(.) %>%\n  pull(row.id)\n\n# filter full grid to only hexagon IDs in AUS\noz_grid <- grid_all[keep_hexes]\n\nggplot() + geom_sf(data = oz_grid)\n\n\n\n\nNow to figure out how many magpie observations are within each hexagon. To do this, first we’ll convert our magpie observation points to an sf spatial object and make sure the point projection is the same as our map of Australia. Then we can use st_intersects() again to return a list, where each data.frame within the list shows which hexagon ID each point is within.\n\nmagpie_points_sf <- filtered_occ %>% \n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n  crs = st_crs(4326))\n\n\nintersect <- st_intersects(magpie_points_sf, oz_grid)\n\nintersect[5:10]\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 1\n\n[[3]]\n[1] 1\n\n[[4]]\n[1] 2\n\n[[5]]\n[1] 1\n\n[[6]]\n[1] 1\n\n\nWith all points within each hexagon in their own separate data.frame, we can use the wicked-fast table() function from base R to count how many points match each hexagon ID, giving us our point counts! A little renaming and wrangling helps to get our counts in the right format.\n\n# condense counts into tibble\ncounts <- as_tibble(table(unlist(intersect)), \n          .name_repair = \"unique\") %>%\n  rename(\"hex_id\" = 1,\n         \"count\" = 2) %>%\n  mutate(hex_id = as.integer(hex_id)) %>%\n  replace_na(list(count = 0))\n\nFinally, we’ll add our count column from complete_counts to our oz_grid. To this, we’ll add a column containing the row number in oz_grid to act as a reference column to join with complete_counts. We will also be sure that oz_grid is an sf object for plotting.\n\noz_grid <- oz_grid %>%\n  as_tibble() %>%\n  mutate(id = row_number()) %>%\n  full_join(counts,\n            by = join_by(id == hex_id)) %>%\n  st_as_sf()\n\noz_grid |> head()\n\nSimple feature collection with 6 features and 2 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 144.8105 ymin: -44.13203 xmax: 148.5632 ymax: -41.63203\nGeodetic CRS:  WGS 84\n# A tibble: 6 × 3\n                                                            geometry    id count\n                                                       <POLYGON [°]> <int> <int>\n1 ((146.5425 -43.63203, 146.8312 -44.13203, 147.4085 -44.13203, 147…     1   493\n2 ((145.6765 -43.13203, 145.9652 -43.63203, 146.5425 -43.63203, 146…     2     7\n3 ((147.4085 -43.13203, 147.6972 -43.63203, 148.2746 -43.63203, 148…     3  1325\n4 ((144.8105 -42.63203, 145.0991 -43.13203, 145.6765 -43.13203, 145…     4     4\n5 ((146.5425 -42.63203, 146.8312 -43.13203, 147.4085 -43.13203, 147…     5  7651\n6 ((145.6765 -42.13203, 145.9652 -42.63203, 146.5425 -42.63203, 146…     6    63\n\n\nFinally, build our map! We’ll use scale_fill_gradientn() to add a nice legend, and standardise our data using a log-transformation so that the colours on our map are scaled to be more informative.\n\nggplot() +\n  geom_sf(data = oz_grid, aes(fill = count), size = .01) +\n  scale_fill_gradientn(colours = c(\"#EEECEA\", \"#E06E53\"), \n                       na.value = \"white\", \n                       trans = \"log10\",\n                       labels = scales::comma_format(),\n                       n.breaks = 6,\n                       guide = guide_colourbar(title = \"Observations\")) +\n  coord_sf(ylim = c(-45, -10), \n           xlim = c(110, 155)) +\n  theme_void()\n\n\n\n\n\n\n\n\nThat’s it! All the extra work does make a difference in this case, providing a better representation of the spread of Mapgies across Australia. Manually constructing hex maps can be useful in other circumstances, too. For example, if we wanted to compare the number of magpies to contextual information within each polygon (such as rainfall or human population data), then manually constructing our own hexagons could help us to combine data from different sources.\nA final point is that we could have achieved the same result by creating polygons first, then querying the ALA for the number of magpie records in each polygon using galah_geolocate(). That’s a bit more challenging, and not worthwhile in this case; but it can be an efficient solution where you require information on more species than there are polygons, for example. You can learn how to do this in this ALA Labs article, if you are interested to learn how!\n\n\nExpand for session info\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31 ucrt)\n os       Windows 10 x64 (build 19044)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_Australia.utf8\n ctype    English_Australia.utf8\n tz       Australia/Sydney\n date     2023-02-06\n pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n dplyr       * 1.1.0   2023-01-29 [1] CRAN (R 4.2.2)\n galah       * 1.5.1   2023-01-13 [1] CRAN (R 4.2.2)\n ggplot2     * 3.3.6   2022-05-03 [1] CRAN (R 4.2.1)\n hexbin      * 1.28.2  2021-01-08 [1] CRAN (R 4.2.1)\n htmltools   * 0.5.4   2022-12-07 [1] CRAN (R 4.2.2)\n ozmaps      * 0.4.5   2021-08-03 [1] CRAN (R 4.2.1)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.1)\n sf          * 1.0-8   2022-07-14 [1] CRAN (R 4.2.1)\n tidyr       * 1.2.0   2022-02-01 [1] CRAN (R 4.2.1)\n\n [1] C:/Users/KEL329/R-packages\n [2] C:/Users/KEL329/AppData/Local/Programs/R/R-4.2.2/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2022-02-17_sunburst-plots-for-taxonomic-data/sunburst-plots.html",
    "href": "posts/2022-02-17_sunburst-plots-for-taxonomic-data/sunburst-plots.html",
    "title": "Sunburst plots for taxonomic data",
    "section": "",
    "text": "Author\nMartin Westgate\n\n\nDate\nFebruary 17 2022\n\n\n\n\n\n\n\n\n\n\n\nTaxonomy is pretty important at the ALA. Every occurrence record in the atlas is linked to a unique taxonomic identifier. These identifiers are themselves drawn from expertly curated taxonomic datasets. This system of classification is so important to our infrastructure that we have a special name for it; the ‘taxonomic backbone’. But what does it look like?\nVisualising trees is not particularly easy for me; I didn’t train in it, and the data structures involved can be a bit complex. More importantly, until recently it was difficult to download detailed taxonomic information from the ALA. Since version 1.3.1 of galah, however, it has been possible to download taxonomic trees using the atlas_taxonomy() function. Let’s have a go at visualising these trees now.\n\nDownloading taxonomic trees\nThe first step is to choose a taxonomic group to represent in tree form. I’ve chosen the chordates (Phylum Chordata) because they aren’t too large a group and the names are fairly well-known. We can specify this within galah using the function galah_identify. The second piece of information we need to supply is how far ‘down’ the tree to travel. I’ve chosen the Order level here using galah_down_to(order); while we could have gone to the Family or even Genus, trying to traverse too many levels (i.e. to Genus or Species) would take a very long time. A full list of accepted ranks can be found by calling show_all_ranks().\n\nlibrary(galah)\nchordate_orders <- galah_call() |>\n  galah_identify(\"chordata\") |>\n  galah_down_to(order) |>\n  atlas_taxonomy()\n\nThe object returned by atlas_taxonomy is slightly unusual; it uses the data.tree package, meaning that the dataset is literally structured like a tree. This is notably different from other representations of networks, such as you might find in igraph, for example. To get an idea of what the data look like, we can use the inbuilt print method for this data type:\n\nlibrary(data.tree)\nprint(chordate_orders, pruneMethod = \"dist\", limit = 10)\n\n                            levelName\n1  Chordata                          \n2   ¦--Cephalochordata               \n3   ¦   °--Amphioxi                  \n4   ¦       °--... 1 nodes w/ 0 sub  \n5   ¦--Tunicata                      \n6   ¦   ¦--Appendicularia            \n7   ¦   ¦   °--... 1 nodes w/ 0 sub  \n8   ¦   ¦--Ascidiacea                \n9   ¦   ¦   °--... 5 nodes w/ 0 sub  \n10  ¦   °--Thaliacea                 \n11  ¦       °--... 3 nodes w/ 0 sub  \n12  °--Vertebrata                    \n13      ¦--Agnatha                   \n14      ¦   °--... 2 nodes w/ 2 sub  \n15      °--Gnathostomata             \n16          °--... 5 nodes w/ 134 sub\n\n\nThis shows there are three nodes directly beneath Chordata in the taxonomic hierarchy, of which the largest (by number of sub-nodes) is the vertebrates (Vertebrata). There is a lot we could do with this tree; each node contains a unique taxonomic identifer, for example, meaning that we could use individual nodes to make new queries using galah. However, for now a useful task is simply to visualise the structure of the whole tree.\n\n\nGetting plot-ready data\nTaxonomic trees are complex. While all species have a Kingdom, Phylum, Order, Class and Family, there are many intermediate categories that are ‘optional’. In practice, this means that when we convert to a data.frame for plotting, there are a lot of missing values; nodes that apply to some rows but not others.\n\ndf_rank <- ToDataFrameTypeCol(chordate_orders, type = \"rank\")\ndf_rank[10:20,] |> tibble::as_tibble() |> print(max_footer_lines = 2)\n\n# A tibble: 11 × 10\n   rank_phylum rank_su…¹ rank_…² rank_…³ rank_…⁴ rank_…⁵ rank_…⁶ rank_…⁷ rank_…⁸\n   <chr>       <chr>     <chr>   <chr>   <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 Chordata    Tunicata  Thalia… <NA>    <NA>    <NA>    <NA>    <NA>    <NA>   \n 2 Chordata    Vertebra… <NA>    Myxini… <NA>    <NA>    <NA>    <NA>    <NA>   \n 3 Chordata    Vertebra… <NA>    Petrom… <NA>    <NA>    <NA>    <NA>    <NA>   \n 4 Chordata    Vertebra… Amphib… Gnatho… Lissam… <NA>    <NA>    <NA>    <NA>   \n 5 Chordata    Vertebra… Amphib… Gnatho… <NA>    Labyri… <NA>    <NA>    <NA>   \n 6 Chordata    Vertebra… Amphib… Gnatho… <NA>    Salien… <NA>    <NA>    <NA>   \n 7 Chordata    Vertebra… Aves    Gnatho… Neogna… <NA>    <NA>    <NA>    <NA>   \n 8 Chordata    Vertebra… Aves    Gnatho… Neogna… <NA>    <NA>    <NA>    <NA>   \n 9 Chordata    Vertebra… Aves    Gnatho… Palaeo… <NA>    Ratitae <NA>    <NA>   \n10 Chordata    Vertebra… Aves    Gnatho… Palaeo… <NA>    Ratitae <NA>    <NA>   \n11 Chordata    Vertebra… Aves    Gnatho… <NA>    <NA>    <NA>    <NA>    <NA>   \n# … with 1 more variable: rank_order <chr>, and abbreviated variable names\n#   ¹​rank_subphylum, ²​rank_class, ³​rank_informal, ⁴​rank_subclass, …\n\n\nThese missing values will show up as empty sections in the resulting diagram, which isn’t ideal. Instead, we can build this data.frame so as to place all nodes in order by row, with empty ‘levels’ being placed at the end. This also avoids the problem where ‘unnamed’ ranks are grouped in the same column. To achieve this, we simply choose a different node attribute (level in this case) to supply to the type argument.\n\ndf_level <- ToDataFrameTypeCol(chordate_orders, type = \"level\")\ndf_level[10:20, ] |> tibble::as_tibble()\n\n# A tibble: 11 × 8\n   level_1  level_2    level_3       level_4     level_5 level_6 level_7 level_8\n   <chr>    <chr>      <chr>         <chr>       <chr>   <chr>   <chr>   <chr>  \n 1 Chordata Tunicata   Thaliacea     Salpida     <NA>    <NA>    <NA>    <NA>   \n 2 Chordata Vertebrata Agnatha       Myxini      Myxini… <NA>    <NA>    <NA>   \n 3 Chordata Vertebrata Agnatha       Petromyzon… Petrom… <NA>    <NA>    <NA>   \n 4 Chordata Vertebrata Gnathostomata Amphibia    Lissam… Anura   <NA>    <NA>   \n 5 Chordata Vertebrata Gnathostomata Amphibia    Labyri… Temnos… <NA>    <NA>   \n 6 Chordata Vertebrata Gnathostomata Amphibia    Salien… Spheno… <NA>    <NA>   \n 7 Chordata Vertebrata Gnathostomata Aves        Neogna… Accipi… <NA>    <NA>   \n 8 Chordata Vertebrata Gnathostomata Aves        Neogna… Phaeth… <NA>    <NA>   \n 9 Chordata Vertebrata Gnathostomata Aves        Palaeo… Ratitae Casuar… <NA>   \n10 Chordata Vertebrata Gnathostomata Aves        Palaeo… Ratitae Dinorn… <NA>   \n11 Chordata Vertebrata Gnathostomata Aves        Accipi… <NA>    <NA>    <NA>   \n\n\nAnother problem in this dataset is the existence of duplicated taxonomic names. This happens because different authorities place the same taxon in different parts of the tree, and while the ALA tries to clean up these issues, some disagreements remain. The code below assumes that each name is only present once, so we have to remove duplicates to proceed. Fortunately there is a function in package base that flags duplcated values as TRUE and unique values as FALSE. We can use this function to identify rows where order is not unique.\n\nlibrary(dplyr)\nkeep_rows <- !duplicated(df_rank$rank_order)\ndf_rank <- filter(df_rank, keep_rows)\ndf_level <- filter(df_level, keep_rows)\n\nThe next step is to determine how to represent this structure in a plot. At the moment we can’t do this, because the data are in ‘wide’ format. Instead, we need to reorder our data so that each node/taxon is represented once, and other plotting aesthetics can be added as additional columns. To achieve this, we first convert to ‘long’ format, preserving information like what row and column each taxonomic label was recorded in.\n\ndf_long <- tibble(\n  row = rep(seq_len(nrow(df_level)), ncol(df_level)),\n  level = rep(seq_len(ncol(df_level)), each = nrow(df_level)),\n  taxon = do.call(c, df_level)) |> \n  filter(!is.na(taxon)) # remove missing values\n\nThen, we can summarize this plot so that each row is a single taxon, recording some metadata about rows and columns from the original dataset\n\ndf_plot <- df_long |>\n  group_by(taxon) |>\n  summarize(\n    xmin = min(row) - 1, \n    xmax = max(row), \n    ymin = level[1] - 1,\n    ymax = level[1])\n     \ndf_plot\n\n# A tibble: 161 × 5\n   taxon             xmin  xmax  ymin  ymax\n   <chr>            <dbl> <int> <dbl> <int>\n 1 Acanthopterygii     61    74     6     7\n 2 Accipititrifomes    15    16     5     6\n 3 Accipitriformes     19    20     4     5\n 4 Actinopterygii      56    96     4     5\n 5 Agnatha             10    12     2     3\n 6 Albuliformes        57    58     6     7\n 7 Amphibia            12    15     3     4\n 8 Amphioxi             0     1     2     3\n 9 Amphioxiformes       0     1     3     4\n10 Anguilliformes      58    59     6     7\n# … with 151 more rows\n\n\n\n\nDrawing\nOur dataset now contains all the information we need to plot the structure of our taxonomic tree. As usual, we’re going to plot this with ggplot2.\n\nlibrary(ggplot2)\nggplot(df_plot) +\n  geom_rect(\n    mapping = aes(\n      xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, \n      group = taxon,\n      fill = ymax),\n    color = \"white\")\n\n\n\n\n\n\n\n\nWhile this is (probably) accurate, it’s not very informative. The most obvious missing element is labels; to add these, we’ll need to determine which nodes are ‘leaves’, and which are ‘branches’. We’ll also want to restrict labelling to larger branches, to avoid the text looking crowded. Finally, there is no need to label leaves with both a rectangle and text; so we’ll remove the leaf rectangles from the plot.\n\ndf_plot <- df_plot |> mutate(\n  x_dist = xmax - xmin,\n  is_leaf = taxon %in% df_rank$rank_order)\n\np <- ggplot() +\n  geom_rect(\n    data = filter(df_plot, !is_leaf),\n    mapping = aes(\n      xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, \n      group = taxon,\n      fill = ymax),\n    color = \"white\")\n\np +\n  # branch labels\n  geom_text(\n    data = filter(df_plot, x_dist > 5),\n    mapping = aes(\n      x = xmin + (x_dist * 0.5), \n      y = ymin + 0.5,\n      label = taxon),\n    color  = \"white\",\n    size = 3) +\n  # leaf labels\n  geom_text(\n    data = filter(df_plot, is_leaf),\n    aes(x = xmin + 0.5, y = ymin, label = taxon),\n    angle = 90,\n    hjust = 0,\n    size = 2.5,\n    color = \"grey20\") \n\n\n\n\n\n\n\n\nThis is better, but not ideal. A much more pleasing look is to use coord_polar() to generate a circular plot; but this leads to linear text on a circular plot, which looks messy. Fortunately, the new package geomtextpath solves this problem. All we have to do is replace geom_text with geom_textpath, leaving all other code the same, and add coord_polar() at the end.\n\nlibrary(geomtextpath)\n\np <- p + \n  geom_textpath(\n    data = filter(df_plot, x_dist > 5),\n    mapping = aes(\n      x = xmin + (x_dist * 0.5), \n      y = ymin + 0.5,\n      label = taxon),\n    color  = \"white\",\n    size = 2.7) +\n  geom_textpath(\n    data = filter(df_plot, is_leaf),\n    aes(x = xmin + 0.5, y = ymin, label = taxon),\n    angle = 90,\n    hjust = 0,\n    size = 2.3,\n    color = \"grey20\") +\n  coord_polar()\np\n\n\n\n\n\n\n\n\nFinally, we can add some finishing touches by changing the color scheme, hiding the background colors and legend, and resizing the y axis so all the labels are visible.\n\nlibrary(viridis)\n\np +\n  scale_fill_viridis(begin = 0, end = 0.9, direction = -1) +\n  lims(y = c(0, 9)) +\n  theme_void() + \n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nDone! This is a fun plot, but there are ways it could be expanded or improved, the most obvious of which is to find ways to add supplementary information. Wouldn’t it be great, for example, to add leaf-level record counts as marginal barplots? Or scale the size of segments to the number of records, rather than the number of clades? While none of these are impossible, I’m going to leave this here for now. I hope you like the result!\n\n\nExpand for session info\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31 ucrt)\n os       Windows 10 x64 (build 19044)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_Australia.utf8\n ctype    English_Australia.utf8\n tz       Australia/Sydney\n date     2023-02-06\n pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package      * version date (UTC) lib source\n data.tree    * 1.0.0   2020-08-03 [1] CRAN (R 4.2.1)\n dplyr        * 1.1.0   2023-01-29 [1] CRAN (R 4.2.2)\n galah        * 1.5.1   2023-01-13 [1] CRAN (R 4.2.2)\n geomtextpath * 0.1.1   2022-08-30 [1] CRAN (R 4.2.1)\n ggplot2      * 3.3.6   2022-05-03 [1] CRAN (R 4.2.1)\n htmltools    * 0.5.4   2022-12-07 [1] CRAN (R 4.2.2)\n sessioninfo  * 1.2.2   2021-12-06 [1] CRAN (R 4.2.1)\n viridis      * 0.6.2   2021-10-13 [1] CRAN (R 4.2.1)\n viridisLite  * 0.4.1   2022-08-22 [1] CRAN (R 4.2.1)\n\n [1] C:/Users/KEL329/R-packages\n [2] C:/Users/KEL329/AppData/Local/Programs/R/R-4.2.2/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2022-05-17_3d-map/3d-map.html",
    "href": "posts/2022-05-17_3d-map/3d-map.html",
    "title": "Download plant species data by hexagon to make a 3D hex map",
    "section": "",
    "text": "Author\nDax Kellie\n\n\nDate\n23 May 2022\n\n\n\n\n\n\n\n\n\n\n\nGrabbing people’s attention in a content-filled world can be difficult. 3D maps can be particularly eye-catching, and thanks to the rayshader package it has become relatively simple to make a beautiful 3D plot with the help of {ggplot2}.\nIn this post, we’ll make a 3D hex map of the number of plant species identified from ALA observations since 2020. This map builds on a previous hex map post, but this time we will use a more unique “grid-to-data” method to download our data, where instead of plotting hexagons over our map after extracting data, we’ll create a grid of hexagons that map to Australia before extracting any data and query the ALA for data for each hexagon. This method is cool because it saves a lot of work wrangling your data to fit your plot later on.\n\nMake a hexagon map\nFirst let’s download the necessary packages\n\n# packages\nlibrary(galah)      # To download species data\nlibrary(rayshader)  # For 3d rendering\nlibrary(tidyverse)  # Data wrangling\nlibrary(here)       # Safe paths\nlibrary(sf)         # Spatial features\nlibrary(ozmaps)     # For map of oz\n\nNow let’s get a map of Australia from the ozmaps package\n\n# get a map and project to WGS84\noz_wgs84 <- ozmap_data(data = \"country\") |>\n  st_transform(crs = st_crs(\"WGS84\"))\n\n## check map\nggplot(oz_wgs84) + geom_sf()\n\n\n\n\nNext let’s create our grid of hexagons and do some tidying to make sure the hexagons are only over the land\n\n# create grid\noz_grid <- st_make_grid(oz_wgs84,\n                        what = \"polygons\",\n                        cellsize = 1.0,\n                        square = FALSE,\n                        flat_topped = TRUE)\n\n# subset to grid cells that are within land\nkeep_hexes <- st_intersects(oz_grid, oz_wgs84)\nkeep_hexes <- as.data.frame(keep_hexes)$row.id\noz_grid <- oz_grid[keep_hexes]\n\nIf we plot our new oz_grid over our map, we can see how the hexagons fill our map of Australia\n\n## check\nggplot() +\n  geom_sf(data = oz_wgs84) +\n  geom_sf(data = oz_grid, fill = NA, color = \"red\")\n\n\n\n\n\n\nDownload species data\nNow that we have our grid of hexagons, we can download data from the ALA using the galah package. Rather than downloading all data on the number of species identified since 2020 and then plotting the data as hexagons, we will make a function that sends individual queries to return the number of species identified within each hexagon.\nOur function get_counts() works in 3 parts:\n\nThe first part does some necessary editing of each Well Known Text (WKT) string so that they are compatible with galah.\nThe second part builds a query to download ALA data, beginning with galah_call(). We add the WKT for each hexagon to our query with galah_geolocate(), specify that we want to return only Plantae and Chlorophyta species with galah_identify(), and filter to only records from 2020 onwards with galah_filter(). We’ll also add galah_filter(profile = \"ALA\") to use a standard ALA data quality filter (known in the ALA as as a data “profile”). We end our query with atlas_counts(type = \"species\") to return counts of species, rather than counts of records (which is the default setting).\nThe final part makes sure that if any hexagons have 0 species identified, they will return a 0 rather than an NA, which triggers an error in R.\n\n\nget_counts <- function(hexagon){\n  \n    # convert to wkt\n    wkt_string <- st_as_text(oz_grid[[hexagon]]) %>%\n      sub(\")))\", \"))\", .) %>%\n      sub(\"POLYGON \", \"POLYGON\", .)\n    \n    # get counts\n    result <- galah_call() |>\n      galah_geolocate(wkt_string) |>\n      galah_identify(\"plantae\", \"chlorophyta\") |>\n      galah_filter(decimalLongitude > 110,\n                   year >= 2020) |>\n      galah_apply_profile(ALA) |>\n      atlas_counts(type = \"species\", # get species counts\n                   limit = NULL)\n    \n    # light formatting to catch errors\n    if(is.null(result)){\n      tibble(count = NA, id = hexagon)\n    }else{\n      result$id <- hexagon\n      result\n    }\n  }\n\nWe can use purrr::map() to run this function recursively for each hexagon. Then we can bind the separate lists into one data.frame with purrr::map_dfr(). As oz_grid is a spatial object containing POLYGONs (which R treats slightly differently to a data.frame), we have to use seq_along(oz_grid) to enable us to run the function for each line, which corresponds to each POLYGON.\nIMPORTANT NOTE: This function will send lots of queries all at once to the ALA, so it is best to use restraint on how many times you run it because it can take a long time and, if run many times in a row, can make it take even longer.\n\n# download number of species for each polygon\ncounts_list <- map(seq_along(oz_grid), get_counts)\n\n# bind lists to data frame\ncounts_df <- map_dfr(counts_list, rbind)\n\ncounts_df now contains a single count of species for each hexagon, indicated by a unique id\n\nhead(counts_df, 10L)\n\n# A tibble: 10 × 2\n   count    id\n   <dbl> <int>\n 1   477     1\n 2   407     2\n 3   544     3\n 4   217     4\n 5  1147     5\n 6   521     6\n 7   596     7\n 8   514     8\n 9   755     9\n10    28    10\n\n\nNow let’s merge our species counts in counts_df to our oz_grid hexagons so we can plot them. To do so, we’ll convert oz_grid to a tibble called oz_df, add a blank count column, and fill that column with the species counts in counts_df for each hexagon by id.\n\n# convert to tibble, attach counts\noz_df <- st_as_sf(oz_grid)\noz_df$count <- NA\noz_df$count[counts_df$id] <- counts_df$count\n\nLet’s see the final result by checking the hexagons with highest species counts\n\n# See top hexagons\noz_df %>%\n  arrange(desc(count)) %>%\n  head(10L)\n\nSimple feature collection with 10 features and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 137.8823 ymin: -38.63203 xmax: 153.7594 ymax: -26.63203\nGeodetic CRS:  WGS 84\n   count                              x\n1   2869 POLYGON ((150.0066 -33.6320...\n2   2428 POLYGON ((144.8105 -37.6320...\n3   2377 POLYGON ((150.8726 -34.1320...\n4   2287 POLYGON ((152.6047 -27.1320...\n5   2284 POLYGON ((152.6047 -28.1320...\n6   2256 POLYGON ((150.0066 -34.6320...\n7   1973 POLYGON ((150.8726 -33.1320...\n8   1849 POLYGON ((151.7387 -27.6320...\n9   1817 POLYGON ((143.9444 -38.1320...\n10  1817 POLYGON ((137.8823 -34.6320...\n\n\n\n\nPlot number of species\nThe first step to making our 3D map is to make a 2D map with ggplot2. I have set the fill of our map to use oz_df’s count column and log transformed it to make our final scale easier to read. The scale_fill_distiller() function has a nice “Greens” palette to make our plant species data look extra planty, and I have added custom limits and labels to make sure the scale is understandable.\n\nhex_map <- ggplot() +\n  geom_sf(\n    data = oz_df,\n    mapping = aes(fill = log10(count + 1)), # log10 + 1 transformed\n    alpha = 1,\n    color = NA) +\n  scale_fill_distiller(name = \"Number of species \\n(since 1 Jan, 2020)\",\n                       type = \"seq\",\n                       direction = 1,\n                       limits = c(0,4),\n                       labels = c(\"10\", \"100\", \"1,000\"),\n                       palette = \"Greens\",\n                       # edit legend to be horizontal-bottom\n                       guide = guide_colorsteps(direction = \"horizontal\",\n                                                label.position = \"top\",\n                                                title.position = \"bottom\",\n                                                title.hjust = 0.5)\n                       ) +\n  # add map\n  geom_sf(data = oz_wgs84,\n          color = NA,\n          fill = NA)  +\n  # crop map\n  coord_sf(xlim = c(110, 155), \n           ylim = c(-45, -10)) +\n  # Adjust text and make aesthetic more minimal\n  theme(title = element_text(face = \"bold\"),\n        legend.title = element_text(size = 19),\n        legend.position = \"bottom\",\n        legend.key.width = unit(28, 'mm'),\n        legend.text = element_text(size = 16),\n        plot.background = element_rect(fill = 'white', colour = 'white'),\n        panel.background = element_rect(fill = 'white', colour = 'white'),\n        axis.title = element_blank()\n        )\n\nhex_map\n\n\n\n\n\n\n\n\n\n\nRender in 3D\nIt’s time to get 3-Dimensional! Using rayshader::plot_gg(), we can render a nice 3d version of our plot1\n\n# Render 3d plot\nplot_gg(hex_map, \n        width = 9, \n        height = 8,\n        scale = 300, # adjust height of 3D transformation\n        windowsize = c(1200, 960), # adjust window of rendered plot\n        fov = 75,    # adjust size/strength of blur around outer edges\n        zoom = 0.37, \n        theta = 320, # adjust left-right rotation of view\n        phi = 33)    # adjust height of view\n\n\n\n\n\n\n\n\n\n\nLooks great! Finally, we can save our plot using render_snapshot()\n\n# save\nSys.sleep(0.2)\nrender_snapshot(here(\"folder\", \"subfolder\", \"3d-map.png\"))\n\nIn this case, a 3D map makes the areas with many and few species very noticeable, which is a useful message to communicate.\nHowever, in general, one should be careful about using 3D plots without first considering the main messages they want people to take away from their data, and whether a 3D figure communicates this better than a 2D alternative. People aren’t as good at quickly interpreting differences in height, shape or location in 3D plots compared to 2D plots. One reason for this weakness is that most 3D plots can only be viewed from a single angle. Depending on what angle the view point of the plot is set to, the literal differences in heights or locations between shapes might change, even if their actual differences in the data they represent don’t change. Looking at a 3D map from above, in the middle, or below changes how the shapes appear, and sometimes they may not accurately represent the true differences between things you want to compare in your plot. This quirk of 3D plots makes it easier for people to misinterpret your plot and, as a result, take away the wrong message from the data (this idea is known as the principle of proportional ink (Tufte, 1983). Carl Bergstrom has written an excellent explanation of why this principle matters in data visualisation)\nEven so, 3D plots can be a beautiful way to see the number of plant species identified in the ALA since 2020. Even cooler, querying species data from the ALA for each hexagon in our map with galah can be an efficient way to download data and reduce data wrangling work later on!\n\n\nExpand for session info\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31 ucrt)\n os       Windows 10 x64 (build 19044)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_Australia.utf8\n ctype    English_Australia.utf8\n tz       Australia/Sydney\n date     2023-01-25\n pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n dplyr       * 1.0.10  2022-09-01 [1] CRAN (R 4.2.1)\n forcats     * 0.5.2   2022-08-19 [1] CRAN (R 4.2.1)\n galah       * 1.5.1   2023-01-13 [1] CRAN (R 4.2.2)\n ggplot2     * 3.3.6   2022-05-03 [1] CRAN (R 4.2.1)\n here        * 1.0.1   2020-12-13 [1] CRAN (R 4.2.1)\n htmltools   * 0.5.4   2022-12-07 [1] CRAN (R 4.2.2)\n ozmaps      * 0.4.5   2021-08-03 [1] CRAN (R 4.2.1)\n purrr       * 0.3.4   2020-04-17 [1] CRAN (R 4.2.1)\n rayshader   * 0.24.10 2021-04-28 [1] CRAN (R 4.2.2)\n readr       * 2.1.3   2022-10-01 [1] CRAN (R 4.2.2)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.1)\n sf          * 1.0-8   2022-07-14 [1] CRAN (R 4.2.1)\n stringr     * 1.5.0   2022-12-02 [1] CRAN (R 4.2.2)\n tibble      * 3.1.8   2022-07-22 [1] CRAN (R 4.2.1)\n tidyr       * 1.2.0   2022-02-01 [1] CRAN (R 4.2.1)\n tidyverse   * 1.3.2   2022-07-18 [1] CRAN (R 4.2.1)\n\n [1] C:/Users/KEL329/R-packages\n [2] C:/Users/KEL329/AppData/Local/Programs/R/R-4.2.2/library\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\n\n\n\n\n\nFootnotes\n\n\nIf you get a weird error related to the scales package, updating to the latest version should fix it: https://github.com/tylermorganwall/rayshader/issues/181#:~:text=Update%20to%20the,install.packages(%27rayshader%27) ↩︎"
  },
  {
    "objectID": "posts/2022-05-23-ggnewscale/ggnewscale.html",
    "href": "posts/2022-05-23-ggnewscale/ggnewscale.html",
    "title": "Multiple colour scales in choropleth maps with {ggnewscale}",
    "section": "",
    "text": "Author\nShandiya Balasubramanium\n\n\nDate\n23 May 2022\n\n\n\n\n\n\n\n\n\n\n\nChoropleth maps visually summarise how variables (like species richness or population density, for example) vary across geographic areas. These maps require two inputs:\n\na geospatial object with information on regional boundaries\na numerical variable that can be mapped to each geographic unit using colour\n\nHere, I walk through the process of mapping the density of plant records from the ALA to geographic bioregions across Australia, using two colour scales to differentiate between marine and terrestrial records.\n\nGet geospatial and count data\nLet’s start by loading the packages we’ll need.\n\nlibrary(galah)\nlibrary(here)\nlibrary(sf)\nlibrary(rmapshaper)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(ggnewscale)\n\nNext, we’ll need some regional boundaries. I think the IBRA7 and IMCRA4 bioregions will work nicely for what we’re planning. These boundaries classify Australia’s landscapes and waters into geographically distinct bioregions based on variables like climate, geomorphology, and species information.\nAfter downloading the data, we can read it in using the sf package and check that it looks correct. Here, I’ve also elected to use ms_simplify() from the rmapshaper package to simplify the geospatial features and speed up computation.\n\n# read in IMCRA shapefile\nimcra_shp <- st_read(here(\"posts\", \n                          \"data\",\n                          \"imcra_mesoscale_bioregions\",\n                          \"imcra4_meso.shp\"), \n                     quiet = TRUE) |> \n  ms_simplify(keep = 0.1)\n\n# read in IBRA shapefile\nibra_shp <- st_read(here(\"posts\",\n                         \"data\",\n                         \"IBRA7_regions\",\n                         \"ibra7_regions.shp\"),\n                    quiet = TRUE) |> \n  ms_simplify(keep = 0.1)\n\nAnd finally, let’s get the number of plant records in the ALA using the galah package, grouped by IBRA or IMCRA region. To do this, we need to know what the ALA calls the IBRA and IMCRA layers.\nUsing the search_fields() function, we can determine that the IBRA layer we’re after is called cl1048 and the IMCRA layer, cl966.\n\nsearch_fields(\"IBRA\")\n\n# A tibble: 4 × 4\n  id     description                                                 type  link \n  <chr>  <chr>                                                       <chr> <chr>\n1 cl3    \"Western Australian Biodiversity Science Research Priority… laye… \"htt…\n2 cl20   \"IBRA 6 Regions Interim Biogeographic Regionalisation of A… laye… \"htt…\n3 cl1049 \"IBRA 7 Subregions IBRA 7 Subregions\"                       laye… \"htt…\n4 cl1048 \"IBRA 7 Regions Interim Biogeographic Regionalisation for … laye… \"htt…\n\nsearch_fields(\"IMCRA\")\n\n# A tibble: 2 × 4\n  id    description                                                  type  link \n  <chr> <chr>                                                        <chr> <chr>\n1 cl966 IMCRA Meso-scale Bioregions IMCRA Meso-scale Bioregions      laye… http…\n2 cl21  IMCRA 4 Regions Integrated Marine and Coastal Regionalisati… laye… http…\n\n\nTo get counts of records from the ALA, we can pass a query with galah_call() and build our query using pipes.\nWe will specify that we only want plant records matching Plantae or Chlorophyta using galah_identify(), apply the default set of ALA data quality filters to remove poor quality records using galah_filter(), group records by region using galah_group_by(), and finally return the counts of records that match all our criteria with atlas_counts().\n\n# counts in IBRA regions\nibra_counts <- galah_call() |>\n  galah_identify(\"plantae\", \"chlorophyta\") |>\n  galah_filter(profile = \"ALA\") |> \n  galah_group_by(\"cl1048\") |>      # IBRA regions\n  atlas_counts()\n\nhead(ibra_counts)\n\n# A tibble: 6 × 2\n  cl1048                      count\n  <chr>                       <int>\n1 Sydney Basin              2375675\n2 South Eastern Highlands   1550937\n3 South East Corner          821505\n4 South Eastern Queensland   812326\n5 NSW North Coast            809581\n6 Murray Darling Depression  743037\n\n# counts in IMCRA regions\nimcra_counts <- galah_call() |>\n  galah_identify(\"plantae\", \"chlorophyta\") |>\n  galah_filter(profile = \"ALA\") |> \n  galah_group_by(\"cl966\") |>      # IMCRA bioregions\n  atlas_counts()\n\nhead(imcra_counts)\n\n# A tibble: 6 × 2\n  cl966                count\n  <chr>                <int>\n1 Victorian Embayments 25356\n2 Shoalwater Coast     19741\n3 Bruny                19562\n4 Lucinda-Mackay Coast 19144\n5 Central Victoria     19112\n6 Flinders             18253\n\n\n\n\nJoin geospatial and count data\nWe now have the two things we need to make a choropleth map:\n\nIBRA/IMCRA boundaries\ncounts of plant records in each region\n\nTo create a plot, we need to combine the geospatial and numeric data. But first, let’s check if the data needs to be tidied.\nAs we’re going to be joining the spatial and count data, we need to be sure that the names of the IBRA/IMCRA regions match in both datasets. To double check that all of our region names match, we’ll use setdiff(). There are no name mismatches when character(0) is returned, but if any region names are returned that means there is a problem somewhere that we need to fix before joining our dataframes.\nWhen we run setdiff(), the IBRA names match perfectly, but there’s a mismatch in two IMCRA names.\n\n# check region names match\nsetdiff(ibra_counts$cl1048, ibra_shp$REG_NAME_7)\n\ncharacter(0)\n\nsetdiff(imcra_counts$cl966, imcra_shp$MESO_NAME)\n\n[1] \"Pilbarra (nearshore)\" \"Pilbarra (offshore)\" \n\n\nReversing the order of IMCRA data frames in setdiff() reveals that that Pilbara is misspelled in the imcra_counts dataset. We can easily change this and confirm both sets of names match before continuing.\n\n# check the reverse for IMCRA names\nsetdiff(imcra_shp$MESO_NAME, imcra_counts$cl966)\n\n[1] \"Pilbara (offshore)\"  \"Pilbara (nearshore)\"\n\n# replace \"Pilbarra\" with \"Pilbara\" \nimcra_counts <- imcra_counts |> \n  mutate(cl966 = str_replace(string = cl966, \n                             pattern = \"Pilbarra\", \n                             replacement = \"Pilbara\"))\n\n# check names match\nsetdiff(imcra_counts$cl966, imcra_shp$MESO_NAME)\n\ncharacter(0)\n\n\nNow let’s check how our data are distributed so we can decide whether we should scale them with a transformation before plotting. Data skewed too far to the right will not show differences very clearly when they are mapped.\nChecking the distribution of counts in each dataset shows a substantial skew to the right.\n\nhist(imcra_counts$count)\nhist(ibra_counts$count)\n\n\n\n\n\n\n\n\n\n\n\nApplying a log-transformation to the count data makes the distribution more symmetrical.\n\nhist(log(imcra_counts$count))\nhist(log(ibra_counts$count))\n\n\n\n\n\n\n\n\n\n\n\nNext, we join the geospatial and numeric data. Along the way, we rename some columns, remove unnecessary columns, calculate counts as a proportion of the area of each region (so we’re plotting density of records, not counts of records), and convert the resulting dataframe into a simple features object.\n\nimcra_join <- imcra_counts |> \n  full_join(y = imcra_shp, by = c(\"cl966\" = \"MESO_NAME\")) |> \n  rename(\"imcra\" = \"cl966\") |> \n  select(imcra, count, AREA_KM2, geometry) |> \n  mutate(density_log10 = log10(count / AREA_KM2)) |> \n  select(imcra, density_log10, geometry) |> \n  st_as_sf()\n\nibra_join <- ibra_counts |> \n  full_join(y = ibra_shp, by = c(\"cl1048\" = \"REG_NAME_7\")) |> \n  rename(\"ibra\" = \"cl1048\") |> \n  select(ibra, count, SQ_KM, geometry) |> \n  mutate(density_log10 = log10(count / SQ_KM)) |> \n  select(ibra, density_log10, geometry) |> \n  st_as_sf()\n\n\n\nMake a map\nFinally, we’ll use the ggnewscale package to apply different colour palettes to the marine and terrestrial data in a choropleth map.\n\nggplot() + \n  geom_sf(data = imcra_join,\n          aes(fill = density_log10),\n          colour = NA) +\n  scale_fill_distiller(name = \"IMCRA\",\n                       type = \"seq\",\n                       palette = \"BuPu\",\n                       direction = 1,\n                       labels = c(\"0.001\", \"0.01\", \"0.1\", \"1\", \"10\"),\n                       guide = guide_colorsteps(direction = \"horizontal\",\n                                                label.position = \"bottom\",\n                                                title.position = \"left\")) +\n  # adds new colour scale\n  ggnewscale::new_scale_fill() +\n  geom_sf(data = ibra_join,\n          aes(fill = density_log10),\n          colour = NA) +\n  scale_fill_distiller(name = \"IBRA\",\n                       type = \"seq\",\n                       palette = \"YlOrBr\",\n                       direction = 1,\n                       labels = c(\"0.1\", \"1\", \"10\", \"100\"),\n                       guide = guide_colorsteps(direction = \"horizontal\",\n                                                label.position = \"bottom\",\n                                                title.position = \"left\")) +\n  # adds a title for both legends\n  annotate(\"text\", \n           x = 133, \n           y = -45.5, \n           label = \"No. of records per square km\",\n           size = 6) +\n  coord_sf(xlim = c(110, 155), ylim = c(-45, -10)) +\n  theme_void() +\n  theme(legend.position = \"bottom\",\n        legend.key.width = unit(12, 'mm'))\n\n\n\n\n\n\n\n\n\n\nSuccess!\nOne thing to note is that we didn’t necessarily have to use ggnewscale here; we could just as easily have combined all the data and plotted them on the same map without keeping the IBRA and IMCRA datasets separate. But, i) it’s nice to be able to differentiate marine and terrestrial regions at a glance, and ii) using two legends also makes it clear that there’s a stark difference in the number of plant records for marine and terrestrial regions.\n\n\nExpand for session info\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31 ucrt)\n os       Windows 10 x64 (build 19044)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_Australia.utf8\n ctype    English_Australia.utf8\n tz       Australia/Sydney\n date     2023-01-25\n pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n dplyr       * 1.0.10  2022-09-01 [1] CRAN (R 4.2.1)\n galah       * 1.5.1   2023-01-13 [1] CRAN (R 4.2.2)\n ggnewscale  * 0.4.7   2022-03-25 [1] CRAN (R 4.2.1)\n ggplot2     * 3.3.6   2022-05-03 [1] CRAN (R 4.2.1)\n here        * 1.0.1   2020-12-13 [1] CRAN (R 4.2.1)\n htmltools   * 0.5.4   2022-12-07 [1] CRAN (R 4.2.2)\n rmapshaper  * 0.4.6   2022-05-10 [1] CRAN (R 4.2.1)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.1)\n sf          * 1.0-8   2022-07-14 [1] CRAN (R 4.2.1)\n stringr     * 1.5.0   2022-12-02 [1] CRAN (R 4.2.2)\n\n [1] C:/Users/KEL329/R-packages\n [2] C:/Users/KEL329/AppData/Local/Programs/R/R-4.2.2/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2022-07-22_sample-bias/sample-bias.html",
    "href": "posts/2022-07-22_sample-bias/sample-bias.html",
    "title": "Quantify geographic sampling bias with {sampbias}",
    "section": "",
    "text": "Being human plays a big role in the species we observe, when we observe them and where we observe them. In particular, we tend to collect more data in areas that are closer to places we live (or have access to) because there are more opportunities to see species in areas we spend more time in than areas that are far away or inaccessible.\nLarge, public datasets like the Atlas of Living Australia are especially prone to this sampling bias because they largely reflect opportunistic observations rather than systematic monitoring programs. However, not all species observations are affected equally by these biases, and it’s useful to quantify how biased data are before interpreting them.\nThanks to the sampbias package, we can easily quantify and compare the effects of these biases on our data, specifically whether data are influenced by cities, roads, airports and rivers.\nThis post expands on a Twitter thread by Dr Ian Brennan to show how sampling bias affects museum records of reptiles. Dr Brennan is currently a Post Doctoral researcher at the Australian National University (ANU). Check out his website to learn more about him and his cool research."
  },
  {
    "objectID": "posts/2022-07-22_sample-bias/sample-bias.html#quolls",
    "href": "posts/2022-07-22_sample-bias/sample-bias.html#quolls",
    "title": "Quantify geographic sampling bias with {sampbias}",
    "section": "Quolls",
    "text": "Quolls\n\nQuolls & Mulgaras\n\n\n\n\n\n\n\n\n\n\n\nLeft: Dasyurus hallucatus (David White CC BY-NC 4.0), Right: Dasycercus blythi (Robert Browne-Cooper CC-BY-NC 3.0 (Au))"
  },
  {
    "objectID": "posts/2022-07-22_sample-bias/sample-bias.html#little-kingfisher",
    "href": "posts/2022-07-22_sample-bias/sample-bias.html#little-kingfisher",
    "title": "Quantify geographic sampling bias with {sampbias}",
    "section": "Little Kingfisher",
    "text": "Little Kingfisher\n\nLittle Kingfisher\n\n\n\n\n\n\n\n\n\n\n\nLeft: Ceyx pusillus (Greg Holland CC BY-NC 4.0), Right: Ceyx pusillus (Graham Winterflood CC-BY-SA 4.0 (Au))"
  },
  {
    "objectID": "posts/2022-07-22_sample-bias/sample-bias.html#mantids",
    "href": "posts/2022-07-22_sample-bias/sample-bias.html#mantids",
    "title": "Quantify geographic sampling bias with {sampbias}",
    "section": "Mantids",
    "text": "Mantids\n\nMantids\n\n\n\n\n\n\n\n\n\n\n\nLeft: Hierodula majuscula (Michael Mcmaster CC BY-NC 4.0), Right: Tenodera australasiae (Reiner Richter CC BY-NC-SA 4.0))"
  },
  {
    "objectID": "posts/2022-07-22_sample-bias/sample-bias.html#green-birdflower",
    "href": "posts/2022-07-22_sample-bias/sample-bias.html#green-birdflower",
    "title": "Quantify geographic sampling bias with {sampbias}",
    "section": "Green birdflower",
    "text": "Green birdflower\n\nGreen birdflower\n\n\n\n\n\n\n\n\n\n\n\nLeft: Crotalaria cunninghamii (Gerald Krygsman CC BY-NC 4.0), Right: Crotalaria cunninghamii (Steve Dew CC BY-NC 4.0))"
  },
  {
    "objectID": "posts/2022-10-12_alpha-hulls/spatial-polygons.html",
    "href": "posts/2022-10-12_alpha-hulls/spatial-polygons.html",
    "title": "Convex and alpha hulls for conservation mapping",
    "section": "",
    "text": "The ability to predict where a species resides is important in conservation ecology, but when a species has very few existing observations (i.e. a data-deficient species), predicting its distribution can be difficult (or impossible) using standard methods for species distributions.\nConvex hulls and alpha hulls are two ways to plot the spatial distribution of data-deficient species, making it possible to calculate metrics that help us predict whether a species is threatened to become extinct (i.e. IUCN metrics).\nRecently, Dr. Marsh and colleagues used alpha hulls to estimate the impact of the 2020 mega bushfires on invertebrates in southern Australia. Since invertebrate data is inherently sparse, alpha hulls are really useful when you only have a handful of records to work with.\nIn this post, we’ll explain the difference between convex hulls and alpha hulls and show you how to make them yourself!"
  },
  {
    "objectID": "posts/2022-10-12_alpha-hulls/spatial-polygons.html#download-data",
    "href": "posts/2022-10-12_alpha-hulls/spatial-polygons.html#download-data",
    "title": "Convex and alpha hulls for conservation mapping",
    "section": "Download data",
    "text": "Download data\nTo illustrate the various spatial polygons you can make, let’s look at an invertebrate species from Dr. Marsh’s study: an endemic damselfly, Austroargiolestes calcaris, commonly known as the Powdered Flatwing\n\n\n\n \n\n\n\n\n\n \n\n\n\n\nA Powdered Flatwing perched on a plant by Reiner Richter CC-BY 4.0\n\nFirst we will load the R packages we’ll need:\n\n# install.packages(\"pacman\")\npacman::p_load(remotes, galah, tidyverse, alphahull, \n               sp, sf, ozmaps, patchwork)\n\nNow let’s use galah to download occurrence records from the Atlas of Living Australia (ALA). Note that you will need to first enter a registered email with the ALA using galah_config before fetching records.\n\n\n\n\n# Add registered email (register at ala.org.au)\ngalah_config(email = \"your-email@email.com\")\n\n\n# Download Powdered flatwing records \ngalah_call() |> \n  galah_identify(\"Austroargiolestes calcaris\") |> \n  galah_filter(profile=\"ALA\") |> \n  galah_select(group = \"basic\") |> \n  atlas_occurrences() -> dfly\n\n# See first 10 rows\ndfly |> head(10L)\n\n# A tibble: 10 × 8\n   decimal…¹ decim…² eventDate           scien…³ taxon…⁴ recor…⁵ dataR…⁶ occur…⁷\n       <dbl>   <dbl> <dttm>              <chr>   <chr>   <chr>   <chr>   <chr>  \n 1     -38.5    147. 2016-11-09 13:00:00 Austro… https:… 20b351… iNatur… PRESENT\n 2     -38      146. 2011-12-20 13:00:00 Austro… https:… d4e2c9… Reiner… PRESENT\n 3     -38.0    146. 2010-01-10 17:48:00 Austro… https:… 0c69fb… iNatur… PRESENT\n 4     -38.0    146. 2009-11-24 13:00:00 Austro… https:… b01df3… Reiner… PRESENT\n 5     -38.0    146. 2009-12-19 13:00:00 Austro… https:… 2ed539… Reiner… PRESENT\n 6     -38.0    146. 2018-02-04 03:40:00 Austro… https:… 586eb7… iNatur… PRESENT\n 7     -38.0    146. 2015-12-28 13:00:00 Austro… https:… 125786… Reiner… PRESENT\n 8     -37.9    145. 2004-10-30 14:00:00 Austro… https:… 9ff508… Reiner… PRESENT\n 9     -37.9    145. 2016-10-31 23:50:00 Austro… https:… fae8d5… ALA sp… PRESENT\n10     -37.9    145. 2019-11-23 01:38:00 Austro… https:… faae5f… iNatur… PRESENT\n# … with abbreviated variable names ¹​decimalLatitude, ²​decimalLongitude,\n#   ³​scientificName, ⁴​taxonConceptID, ⁵​recordID, ⁶​dataResourceName,\n#   ⁷​occurrenceStatus\n\n\nBefore we can plot anything, we will also need to remove all duplicated values and any NA values!\n\n# Remove duplicates & NAs\ndfly |> \n  filter(!duplicated(decimalLongitude) & !duplicated(decimalLatitude)) |> \n  filter(!is.na(decimalLongitude) & !is.na(decimalLatitude) ) -> dfly_clean"
  },
  {
    "objectID": "posts/2022-10-12_alpha-hulls/spatial-polygons.html#map-a-convex-hull",
    "href": "posts/2022-10-12_alpha-hulls/spatial-polygons.html#map-a-convex-hull",
    "title": "Convex and alpha hulls for conservation mapping",
    "section": "Map a convex hull",
    "text": "Map a convex hull\nA convex hull is a way to draw around all the points of a species on a map with as few lines as possible. It’s defined as the smallest polygon that encloses all the points in the data set.\nTo plot a convex hull on a map, we can use chull() to compute a convex hull from our cleaned Powdered Flatwing data. chull() computes a series of points that make up our convex hull.\n\n# Compute convex hull\ndfly_clean |> \n  dplyr::select(decimalLongitude, decimalLatitude) |>  \n  chull() -> dfly_chull\n\ndfly_chull\n\n [1] 147 146   1  19  35  50 132 135 222 388 346\n\n\nNext, we join the first point of the hull vector to the last point, creating a closed outline which can be plotted on a map.\n\n# Join first point of hull to the last point\ndfly_chull_pts <- c(dfly_chull, dfly_chull[1])\n\nNow we can get a map of Australia from the {ozmaps} package and use st_transform() to make sure it has the correct projection of 4326.\n\n# Get map of Australia\naus <- st_transform(ozmaps::ozmap_country, 4326)\n\nAnd finally, we plot our Powdered Flatwing occurrence records and its convex hull on a map!\n\n# Plot occurrences and convex hull\nggplot() + \n  geom_sf(data = aus, \n          colour = \"black\", \n          fill = \"white\")  + \n  geom_point(data = dfly_clean, \n             mapping = aes(decimalLongitude, decimalLatitude), \n             colour = \"black\", size = 0.8) + \n  geom_polygon(data = dfly_clean[dfly_chull_pts, ], \n               mapping = aes(decimalLongitude, decimalLatitude), \n               fill = \"orange\", \n               colour = \"black\", \n               alpha = 0.5) + \n  coord_sf(xlim=c(142, 152), \n           ylim=c(-32,-44)) +\n  labs(title = \"Convex hull\", \n       x = \"Longtitude (DD)\", \n       y = \"Latitude (DD)\") + ## DD here stands for decimal degrees\n  theme_bw()"
  },
  {
    "objectID": "posts/2022-10-12_alpha-hulls/spatial-polygons.html#what-is-an-alpha-hull",
    "href": "posts/2022-10-12_alpha-hulls/spatial-polygons.html#what-is-an-alpha-hull",
    "title": "Convex and alpha hulls for conservation mapping",
    "section": "What is an alpha hull?",
    "text": "What is an alpha hull?\nLike a convex hull, an alpha hull is also a way to draw the smallest polygon that encloses all the points in a data set. However, alpha hulls differ because they use an alpha parameter to control how tightly the boundary fits around a set of points. This method creates concave, arched edges that fit around occurrence records more tightly. A tighter boundary around our points helps us avoid over-predicting the range of a species.\nTo illustrate, here are three alpha hulls with increasing values for alpha. Notice as the alpha value increases, the tightness of our boundary decreases.\n\n\nCode\n# Compute alpha shapes and store in list column within a tibble\ntibble(\n  alpha_value = c(1, 2, 5),\n  ahull_ls = map(.x = c(1, 2, 5),\n                 .f = ~ dfly_clean |> \n                   select(decimalLongitude, decimalLatitude) |> \n                   ahull(alpha = .x)) \n) -> dfly_ahulls\n\n\n# Transform alpha hull to an `sp` object and set map projection to 4326\nset_map_proj <- function(sp_obj){\nsp_obj@proj4string <- sp::CRS(\"EPSG:4326\") \n\nsp_obj\n}\n\ndfly_ahulls |> \n  mutate(ahull_sp = map(.x = ahull_ls,\n                        .f = hull2spatial::ahull2poly),\n         ahull_sp = map(.x = ahull_sp,\n                        .f = set_map_proj)\n         ) -> dfly_ahulls\n\n\n# Transform `sp` object into a `sf` object \ndfly_ahulls |> \n  mutate(ahull_sf = map(.x = ahull_sp,\n                        .f = st_as_sf)\n         ) -> dfly_ahulls\n\n# Transform occurrences into `sf` object for plotting\nst_as_sf(dfly_clean, \n         coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n         crs = 4326) -> dfly_sf\n\n## A function to compose map \nplot_ahull_fun <- function(ahull_sf, title = NULL){\n  p <- ggplot() + \n    geom_sf(data = aus, colour = \"black\", fill = \"white\")  +\n    geom_sf(data = dfly_sf, colour = \"black\", size = 0.5) +  \n    geom_sf(data = ahull_sf, fill = \"orange\", alpha = 0.5) +\n    coord_sf(xlim=c(142, 152),ylim=c(-32,-44)) +\n    ggtitle(paste(\"a = \", as.character(title))) +\n    labs(x = \"Longtitude (DD)\", y = \"Latitude (DD)\") + \n    theme_bw(base_size = 12)\n  \n  p\n}\n\ndfly_ahulls |> \n  mutate(ahull_maps = map2(.x = ahull_sf,\n                           .y = alpha_value,\n                           .f = ~ plot_ahull_fun(.x , .y)) \n  ) -> dfly_ahulls\n\n\n\n\n\n\n\n\n\n\n\nAlpha = 2 is the alpha value we’ve most commonly come across in research, and is the value recommended by the IUCN for various forms of species vulnerability analysis.\nSo, let’s learn how to make the a = 2 plot above!"
  },
  {
    "objectID": "posts/2022-10-12_alpha-hulls/spatial-polygons.html#map-an-alpha-hull",
    "href": "posts/2022-10-12_alpha-hulls/spatial-polygons.html#map-an-alpha-hull",
    "title": "Convex and alpha hulls for conservation mapping",
    "section": "Map an alpha hull",
    "text": "Map an alpha hull\nTo make an alpha hull, we will rely on the hull2spatial package (developed by Cecina Babich Morrow). This package allows us to convert “ahull” objects into ggplot-friendly objects (to learn more, check out their blog post about the package).\nInstall the package from GitHub using:\n\nremotes::install_github(\"babichmorrowc/hull2spatial\")\nlibrary(hull2spatial)\n\nTo compute our alpha hull, we’ll provide the longitude and latitude coordinates of our data points to the ahull() function, and set alpha = 2. ahull() creates a list object with far more complexity than our convex hull. A nice way to understand the difference is to look at the first 5 rows of the arcs component of our list dfly_ahull, which stores information like the center and radius of each arch in our alpha hull.\n\n# Compute an alpha hull\ndfly_clean |> \n  dplyr::select(decimalLongitude, decimalLatitude) |> \n  ahull(alpha = 2) -> dfly_ahull\n\n# See first 5 values of `arcs` component of list\ndfly_ahull$arcs |> head(5L)\n\n           c1        c2 r       v.x       v.y       theta end1 end2\n[1,] 144.8341 -39.83458 2 0.3890667 0.9212096 0.009959896    2    4\n[2,] 144.8227 -39.82989 2 0.3508991 0.9364133 0.037253656    4   10\n[3,] 144.7963 -39.82087 2 0.3060905 0.9520024 0.024179028   10   19\n[4,] 143.7084 -39.02735 2 0.8254355 0.5644964 0.002581065   19   35\n[5,] 143.6389 -38.91884 2 0.8574929 0.5144958 0.002478157   35   50\n\n\nNext we’ll transform our alpha hull and occurrence points into spatial objects for plotting.\nThe ahull2poly() function converts our alpha hull to one type of spatial object (an sp object), but we’ll use st_as_sf() to convert our result to an sf object (because it’s easier to plot) and set our map projection to 4326. We’ll do the same for our damselfly occurrence points.\n\n# Transform  `ahull` into spatial object, convert to sf, set coordinates\nhull2spatial::ahull2poly(dfly_ahull) |> \n  st_as_sf() |> \n  st_set_crs(st_crs(aus)) -> dfly_sf_ahull\n\n# Convert occurrence points to `sf` for plotting\ndfly_clean |> \n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n           crs = 4326) -> dfly_sf\n\nFinally, we can create our plot!\n\n# Plot the occurrences and alpha hull\nggplot() + \n  geom_sf(data = aus, colour = \"black\", fill = \"white\")  +\n  geom_sf(data = dfly_sf, colour = \"black\", size = 0.5) +  \n  geom_sf(data = dfly_sf_ahull, fill = \"orange\", alpha = 0.5) +\n  coord_sf(xlim=c(142, 152),ylim=c(-32,-44)) +\n  ggtitle(\"Alpha hull\") +\n  labs(x = \"Longtitude (DD)\", y = \"Latitude (DD)\") + \n  theme_bw()\n\n\n\n\n\n\n\n\n\nAlpha hull with filtered observations\nCitizen science data are often excluded from scientific analyses due to poor data quality e.g. rare species can be misidentified by someone who’s not an expert. Although a strict data criteria will reduce the number of data points, we can still compute and plot alpha hulls for the Powdered Flatwing - this is the beauty of them!\nLet’s repeat exactly the same steps as above for generating an alpha hull, but only use a subset of our damselfly observations that comes from specimen data. We can do this by specifying the basisOfRecord with galah_filter().\n\n# Create a vector excluding human observations\ninstitution_only <- c(\"PRESERVED_SPECIMEN\", \"LIVING_SPECIMEN\", \n                   \"MACHINE_OBSERVATION\", \"MATERIAL_SAMPLE\")\n\ngalah_call() |> \n  galah_identify(\"Austroargiolestes calcaris\") |> \n  galah_filter(basisOfRecord == institution_only,\n               profile = \"ALA\") |> \n  galah_select(group = \"basic\") |> \n   atlas_occurrences() -> dfly_specionly\n\nBelow is our alpha hull of our specimen-only damselfly data. You’ll notice that there are two separate hulls in this map! This is another benefit of using an alpha hull over a convex hull. The mathematical constraints of a convex hull mean all points must be contained within a single polygon - this can lead to an over-estimation of a species’ range."
  },
  {
    "objectID": "posts/2022-10-12_alpha-hulls/spatial-polygons.html#a-real-life-example",
    "href": "posts/2022-10-12_alpha-hulls/spatial-polygons.html#a-real-life-example",
    "title": "Convex and alpha hulls for conservation mapping",
    "section": "A real-life example",
    "text": "A real-life example\nAlpha hulls, and their ability to generate multiple hulls when data is sparse, can help us understand how sensitive certain species are to environmental change over time, even when species have few existing observations.\nFor example, Dr. Takach and their team wanted to investigate how the distribution of mammals in the tropical savanna like Mesembriomys gouldii (the Black-Footed Tree Rat) shrink or expand in response to pressures like habitat loss and changing climate. Using alpha hulls, they found that the ecological niche of this species has shrunk due to a loss of suitable habitat over time.\n\n\n\n \n\n\n\n\n\n \n\n\n\n\nA Black-Footed Tree Rat perched on a branch by Colin Trainor CC-BY-NC 4.0\n\nThe published paper didn’t provide a visual of this species’ distribution, so we’ve made a map below with ALA data to show the change in distribution over time:\n\n\nCode\n# Download records\ngalah_call() |> \n  galah_identify(\"Mesembriomys gouldii\") |> \n  galah_filter(profile = \"ALA\") |> \n  galah_select(group = \"basic\") |> \n  atlas_occurrences() -> tree_rat\n\n# Remove duplicates and NAs\ntree_rat |> \n  filter(! duplicated(decimalLongitude) & ! duplicated(decimalLatitude)) |> \n  filter(! is.na(decimalLongitude) & ! is.na(decimalLatitude) ) -> tree_ratclean\n\n# Convert occurrence points to sf for plotting\ntree_ratclean |> \n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n           crs = 4326) -> tree_rat_sf\n\n# Compute alpha hull\ntree_ratclean |> \n  select(decimalLongitude, decimalLatitude) |> \n  ahull(alpha = 2) -> tree_rat_ahull\n\n# Transform `ahull` to `sf`, set projection\nhull2spatial::ahull2poly(tree_rat_ahull) |> \n  st_as_sf() |>\n  st_set_crs(st_crs(aus)) -> tree_rat_sf_ahull\n\n# Convert occurrence points to sf for plotting\ntree_ratclean |> \n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n           crs = 4326) -> tree_rat_sf\n\n# Get map of Australia & set projection\naus <- st_transform(ozmaps::ozmap_country, 4326)\n\n#---\n\n# Download tree rat records after 2000\ngalah_call() |>\n  galah_identify(\"Mesembriomys gouldii\") |>\n  galah_filter(profile = \"ALA\",\n               year >= 2000,) |>\n  galah_select(group = \"basic\") |>\n  atlas_occurrences() -> Rtree_rat\n\n# Remove duplicates & exclude NAs\nRtree_rat |> \n  filter(!duplicated(decimalLongitude) & !duplicated(decimalLatitude)) |> \n  filter(!is.na(decimalLongitude) & !is.na(decimalLatitude) ) -> Rtree_ratclean\n\n# Compute an alpha hull for our specimen only occurrences\nRtree_ratclean |> \n  select(decimalLongitude, decimalLatitude) |> \n  ahull(alpha = 2) -> Rtree_rat_ahull\n\n# Transform `ahull` to sf, set coordinates\nhull2spatial::ahull2poly(Rtree_rat_ahull) |> \n  st_as_sf() |> \n  st_set_crs(st_crs(aus)) -> Rtree_rat_sf_ahull\n\n# Transform occurrence points to sf for plotting \nRtree_ratclean |> \n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n           crs = 4326) -> Rtree_rat_sf\n\n#---\n\n# Nice title\nrat_title <- expression(italic(\"Mesembriomys gouldii \"), \"alpha hulls\")\n\n# Plot!\nggplot() + \n  geom_sf(data = aus, colour = \"black\", fill = \"white\")  +\n  geom_sf(data = tree_rat_sf_ahull, aes(fill = \"chartreuse3\") ,alpha = 0.5, colour = \"black\", position = \"identity\") +\n    geom_sf(data = Rtree_rat_sf_ahull, aes(fill = \"blueviolet\"), alpha = 0.5, colour = \"black\", position = \"identity\") +\n  scale_fill_identity(guide = \"legend\",\n                      name = \"Record date ranges\",\n                      labels = c('2000 Onwards', 'All Records')) +\n  guides(colour = guide_legend(override.aes = list(alpha = 0.1))) +\n  coord_sf(xlim=c(125, 145),ylim=c(-20,-10)) +\n  ggtitle(rat_title) +\n  labs(x = \"Longtitude (DD)\", y = \"Latitude (DD)\") + \n  theme_bw() +\n  theme(legend.position = \"bottom\") -> combinedtree_rat_ahull_p"
  },
  {
    "objectID": "posts/2022-10-12_alpha-hulls/spatial-polygons.html#final-thoughts",
    "href": "posts/2022-10-12_alpha-hulls/spatial-polygons.html#final-thoughts",
    "title": "Convex and alpha hulls for conservation mapping",
    "section": "Final thoughts",
    "text": "Final thoughts\nWhile sophisticated tools for modelling species distribution exist, they require a lot of data to make reliable estimates. Convex polygons and alpha hulls are flexible alternatives that can help us understand dynamic changes to distributions of understudied or vulnerable data-deficient species.\n\n\nExpand for session info\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31 ucrt)\n os       Windows 10 x64 (build 19044)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_Australia.utf8\n ctype    English_Australia.utf8\n tz       Australia/Sydney\n date     2023-02-01\n pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package       * version date (UTC) lib source\n alphahull     * 2.5     2022-06-16 [1] CRAN (R 4.2.1)\n dplyr         * 1.0.10  2022-09-01 [1] CRAN (R 4.2.1)\n forcats       * 0.5.2   2022-08-19 [1] CRAN (R 4.2.1)\n galah         * 1.5.1   2023-01-13 [1] CRAN (R 4.2.2)\n ggplot2       * 3.3.6   2022-05-03 [1] CRAN (R 4.2.1)\n htmltools     * 0.5.4   2022-12-07 [1] CRAN (R 4.2.2)\n hull2spatial  * 0.1.0   2022-10-12 [1] Github (babichmorrowc/hull2spatial@921594f)\n ozmaps        * 0.4.5   2021-08-03 [1] CRAN (R 4.2.1)\n pacman        * 0.5.1   2019-03-11 [1] CRAN (R 4.2.1)\n patchwork     * 1.1.2   2022-08-19 [1] CRAN (R 4.2.1)\n purrr         * 0.3.4   2020-04-17 [1] CRAN (R 4.2.1)\n readr         * 2.1.3   2022-10-01 [1] CRAN (R 4.2.2)\n remotes       * 2.4.2   2021-11-30 [1] CRAN (R 4.2.1)\n sessioninfo   * 1.2.2   2021-12-06 [1] CRAN (R 4.2.1)\n sf            * 1.0-8   2022-07-14 [1] CRAN (R 4.2.1)\n sp            * 1.5-0   2022-06-05 [1] CRAN (R 4.2.1)\n stringr       * 1.5.0   2022-12-02 [1] CRAN (R 4.2.2)\n tibble        * 3.1.8   2022-07-22 [1] CRAN (R 4.2.1)\n tidyr         * 1.2.0   2022-02-01 [1] CRAN (R 4.2.1)\n tidyverse     * 1.3.2   2022-07-18 [1] CRAN (R 4.2.1)\n xaringanExtra * 0.7.0   2022-07-16 [1] CRAN (R 4.2.1)\n\n [1] C:/Users/KEL329/R-packages\n [2] C:/Users/KEL329/AppData/Local/Programs/R/R-4.2.2/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/2023-01-12_counting-points-in-shapefiles/counting-points.html",
    "href": "posts/2023-01-12_counting-points-in-shapefiles/counting-points.html",
    "title": "Counting points in multipolygon shapefiles for choropleth mapping",
    "section": "",
    "text": "Choropleth maps are an excellent way to visualise differences in variables (eg. number of species observed) across several geographic regions (eg. countries, states, study areas). Often, creating a choropleth map from species observations requires two things:\nHowever, to create a choropleth map of species observations requires us to summarise our points to a single statistic for each polygon of our shapefile. This conversion from points to polygons can sometimes be tricky!\nHere, we show you how to extract and count the number of points inside each polygon of a shapefile to create a choropleth map of the number of species observations per km2 in each suburb of the Australian Capital Territory (ACT)."
  },
  {
    "objectID": "posts/2023-01-12_counting-points-in-shapefiles/counting-points.html#download-data",
    "href": "posts/2023-01-12_counting-points-in-shapefiles/counting-points.html#download-data",
    "title": "Counting points in multipolygon shapefiles for choropleth mapping",
    "section": "Download data",
    "text": "Download data\nFirst we will load the R packages that we need:\n\nlibrary(galah)\nlibrary(here) \nlibrary(rmapshaper) \nlibrary(tidyverse) \nlibrary(sf)\nlibrary(ggtext)\n\n\nDownload shapefile\nNext we will need a shapefile. You can find many shapefiles online from reputable sources. For this example, I’ve downloaded a shapefile of suburb boundaries in the city of Canberra, ACT from the ACT’s open-access map database.\nUsually when you download a shapefile, it is compressed within a zip folder. Save this downloaded zip folder in a local folder inside your current R project. If you need to unzip your folder, you can do so with the following code:\n\nzip_folder <- here(\"folder-name\", \"shapefile-folder-name.zip\")\noutput_dir <- \"folder-name-to-save-unzipped-files\" \nunzip(zip_folder, exdir = output_dir) \n\nNow we load this unzipped shapefile into R. To save space, we’ll remove some complexity from our shapefile polygons with ms_simplify() from the {rmapshaper} package.\nThe actsuburbs shapefile contains both suburb boundaries and “district” boundaries, which can encompass several suburbs. To avoid confusion, we will remove districts using filter(LOC_CLASS != \"District\"). We’ll also use st_make_valid() to make sure any weird invalid geometries in our shapefile are made valid, and therefore plot correctly.\n\nactsuburbs <- st_read(here(\"folder-name\",\n                           \"folder-name-2\",\n                           \"shapefilename.shp\")) |>\n                     ms_simplify(keep = 0.1) |> \n  st_transform(crs = st_crs(\"WGS84\")) |> \n  st_make_valid() |> \n  filter(LOC_CLASS != \"District\")\n\n\n\n\nNow to see if our shapefile plots correctly, we can use geom_sf() (and it looks like it does!)\n\nggplot() +\n  geom_sf(data = actsuburbs) +\n  theme(axis.text.x = element_text(angle = -90, hjust = 0))\n\n\n\n\n\n\nDownload species observations\nNext let’s use the {galah} package to download bird occurrence records from the Atlas of Living Australia (ALA).\nWe can download all Aves (bird) data provided by BirdLife Australia within the ACT by using galah_filter() to narrow our download. We’ll also add ALA’s data profile, or what the ALA calls a set of data quality filters to remove suspicious records, using galah_apply_profile(ALA).\nYou will need to provide a registered email with the ALA using galah_config() before retrieving records.\n\ngalah_config(email = \"your-email@email.com\") \n\n\n\n\n\nbirdocc <- galah_call() |> \n  galah_identify(\"Aves\") |> \n  galah_apply_profile(ALA) |>\n  galah_filter(stateProvince == \"Australian Capital Territory\",\n               dataProviderName == \"BirdLife Australia\") |>  \natlas_occurrences()\n\nbirdocc |> head(8L)\n\n# A tibble: 8 × 8\n  decimalL…¹ decim…² eventDate           scien…³ taxon…⁴ recor…⁵ dataR…⁶ occur…⁷\n       <dbl>   <dbl> <dttm>              <chr>   <chr>   <chr>   <chr>   <chr>  \n1      -35.9    149. 2013-10-11 13:00:00 Dacelo… https:… 0d70c8… BirdLi… PRESENT\n2      -35.9    149. 2013-10-11 13:00:00 Hirund… https:… 9fef9b… BirdLi… PRESENT\n3      -35.9    149. 2013-10-11 13:00:00 Corvus… https:… a947cb… BirdLi… PRESENT\n4      -35.9    149. NA                  Petroi… https:… 8043c6… BirdLi… PRESENT\n5      -35.9    149. NA                  Cormob… https:… dda4cd… BirdLi… PRESENT\n6      -35.9    149. NA                  Melith… https:… d83fec… BirdLi… PRESENT\n7      -35.9    149. NA                  Pachyc… https:… 3289d0… BirdLi… PRESENT\n8      -35.9    149. NA                  Pardal… https:… 426455… BirdLi… PRESENT\n# … with abbreviated variable names ¹​decimalLatitude, ²​decimalLongitude,\n#   ³​scientificName, ⁴​taxonConceptID, ⁵​recordID, ⁶​dataResourceName,\n#   ⁷​occurrenceStatus\n\n\n\nFor those unfamiliar with Australian geography, the ACT is located here:"
  },
  {
    "objectID": "posts/2023-01-12_counting-points-in-shapefiles/counting-points.html#count-points-in-each-polygon",
    "href": "posts/2023-01-12_counting-points-in-shapefiles/counting-points.html#count-points-in-each-polygon",
    "title": "Counting points in multipolygon shapefiles for choropleth mapping",
    "section": "Count points in each polygon",
    "text": "Count points in each polygon\nTo prepare our data, we’ll convert each observation into a format suitable for spatial mapping. st_as_sf() transforms each point into an sf spatial object (which plots nicely with {ggplot2}). We’ll also make sure the points are projected to crs = set_crs(\"WGS84\"), the same as our shapefile, so that the points line up correctly.\n\nbird_points_sf <- birdocc |> \n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n  crs = st_crs(\"WGS84\"))\n\nNow we’ll find and count how many points are in each of our suburbs.\nThe st_intersects() function checks whether each point is within, or “intersects”, a specified POLYGON and then marks it as TRUE or FALSE in a matrix. Using st_intersects() in a loop with pmap() allows us to run st_intersects() on each row of a supplied list.\nIn our case, because each row of actsuburbs$geometry corresponds to each suburb, pmap_dbl() recursively checks which points are within each of our ACT suburbs! Adding lengths() around st_intersects() will count the number of rows returned for each suburb list, returning the total number of points that intersect each suburb. 1. We’ve saved this count in a new column bird_count.\n\n\n\n\n\n\nWarning\n\n\n\nThis function takes ~3.5 minutes to run\n\n\n\nact_counts <- actsuburbs |> \n  mutate(bird_count = pmap_dbl(.l = list(x = actsuburbs$geometry),\n                           .f = function(x) {\n                             lengths(st_intersects(x, bird_points_sf))\n                             }))\n\nact_counts |> \n  select(LOC_NAME, bird_count) |> \n  head(8L) # see sample of counts\n\nSimple feature collection with 8 features and 2 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 149.0563 ymin: -35.48032 xmax: 149.2188 ymax: -35.15856\nGeodetic CRS:  WGS 84\n   LOC_NAME bird_count                       geometry\n1     Acton        670 POLYGON ((149.128 -35.28592...\n2   Ainslie        120 POLYGON ((149.1374 -35.2583...\n3    Amaroo         50 POLYGON ((149.1157 -35.1682...\n4    Aranda         38 POLYGON ((149.0876 -35.2551...\n5     Banks          0 POLYGON ((149.1019 -35.4803...\n6    Barton        755 POLYGON ((149.1295 -35.3070...\n7     Beard          0 POLYGON ((149.2156 -35.3407...\n8 Belconnen       1521 POLYGON ((149.0789 -35.2304...\n\n\nShowing the total number of bird observations on a choropleth map can be misleading because areas that are larger might have more records simply because they are large areas! It’s a good idea to standardise your data to avoid this bias. In this case, we will show the number of observations per square kilometer.\nTo do this, we will use sf::st_area() to help us get the area per m2 of our suburbs & convert it to km2 by dividing by 1000, saving this in a new column area_km2. Then we’ll divide our bird_count by area_km2.\n\nact_counts <- act_counts |>\n  rowwise() |> \n  mutate(area_km2 = as.integer(st_area(geometry))/1000,\n         counts_km2 = bird_count/area_km2) |>\n  replace_na(list(counts_km2 = 0))\n\nact_counts |> rmarkdown::paged_table() # final data frame\n\n\n\n  \n\n\n\nIt’s a good idea to check the distribution of our data before we plot so we know what we should expect it to look like. If we check our bird counts, we can notice that our count data is skewed because many regions have lower numbers of observations, and only a few regions have very high numbers of observations.\n\nhist(act_counts$bird_count, main = \"bird_count distribution\")\n\n\n\n\nLog transformation will reduce the skew in our data, ultimately making our final choropleth map easier to interpret. We will handle this when we make our ggplot in the final step!"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n\n\n\n\n  \n\n\n\n\nCounting points in multipolygon shapefiles for choropleth mapping\n\n\n\n\n\nChoropleth maps are an excellent way to visualise numbers of observations, but when using point data, calculating the number of points in each polygon can be difficult when using shapefiles. Here we demonstrate how to extract and summarise the number of points in each polygon to create a choropleth map.\n\n\n\n\n\n\nFeb 6, 2023\n\n\nOlivia Torresan, Dax Kellie\n\n\n9 min\n\n\n\n\n\n\n  \n\n\n\n\nConvex and alpha hulls for conservation mapping\n\n\n\n\n\nConvex hulls and alpha hulls are wonderful alternatives for visualising species distributions when a species has very few existing observations. Here, we will show you how to create these spatial polygons using data from the ALA.\n\n\n\n\n\n\nOct 20, 2022\n\n\nMargot Schneider, Fonti Kar\n\n\n13 min\n\n\n\n\n\n\n  \n\n\n\n\nQuantify geographic sampling bias with {sampbias}\n\n\n\n\n\nHuman biases play a large role in the data we collect about species. Here we show a simple method to quantify the bias of roads, cities, rivers and airports on species observations of legless lizards in the Northern Territory\n\n\n\n\n\n\nAug 8, 2022\n\n\nDax Kellie\n\n\n10 min\n\n\n\n\n\n\n  \n\n\n\n\nMultiple colour scales in choropleth maps with {ggnewscale}\n\n\n\n\n\nUsing multiple colour scales can be a great way to visually differentiate between geographic categories on a map. Here, we demonstrate this by creating a choropleth map to represent the density of plant records from the ALA across bioregions in Australia, and add multiple colour scales to differentiate marine and terrestrial records\n\n\n\n\n\n\nMay 31, 2022\n\n\nShandiya Balasubramaniam\n\n\n9 min\n\n\n\n\n\n\n  \n\n\n\n\nDownload plant species data by hexagon to make a 3D hex map\n\n\n\n\n\nMaking plots eye-catching can be useful for science communication. Here, we show how to make 3D plots in R with the rayshader package by visualising the number of species identified from ALA observations since 2020\n\n\n\n\n\n\nMay 23, 2022\n\n\nDax Kellie\n\n\n11 min\n\n\n\n\n\n\n  \n\n\n\n\nSunburst plots for taxonomic data\n\n\n\n\n\nSince version 1.3.1 of {galah}, it has been possible to download taxonomic data using a ‘tree’ format from the {data.tree} package. Here I’ll demonstrate some ideas for plotting these trees using circular diagrams.\n\n\n\n\n\n\nFeb 17, 2022\n\n\nMartin Westgate\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\nHex maps for species occurrence data\n\n\n\n\n\nThere are hundreds of color palettes in the R ecosystem, but sometimes we might want to use colors from a specific image. Here I show how to use the paletter package to create a color palette for the 2020 Eucalypt of the Year: the Western Australian Gimlet.\n\n\n\n\n\n\nMar 1, 2021\n\n\nMatilda Stevenson, Dax Kellie, Martin Westgate\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\nCreating a color palette from an image\n\n\n\n\n\nThere are hundreds of color palettes in the R ecosystem, but sometimes we might want to use colors from a specific image. Here I show how to use the paletter package to create a color palette for the 2020 Eucalypt of the Year: the Western Australian Gimlet.\n\n\n\n\n\n\nJan 3, 2021\n\n\nMartin Westgate\n\n\n4 min\n\n\n\n\n\n\nNo matching items"
  }
]